{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hi there \ud83d\udd96! \u00b6 My name is \ud83d\udc68Alejandro Piad Morffis. Here are some things about me: I live in Havana, \ud83c\udde8\ud83c\uddfaCuba, but I'm temporally located in Alicante, \ud83c\uddea\ud83c\uddf8Spain. I'm currently finishing a \ud83c\udf93PhD in Computer Science. In my free time, I also enjoy \ud83d\udcbb coding (mostly in \ud83d\udc0dPython), \ud83c\udfaeplaying video games (sadly not much lately), and \u270f\ufe0f writing . My two passions are \ud83d\udcdateaching and \u2697\ufe0f researching . I teach Programming, Compilers, AI, and a bunch of other stuff at the University of Havana. I also do research there, mostly on how to use artificial intelligence to better understand human languages. You can find me online on \ud83d\udde8\ufe0f Twitter , \ud83d\udcbc LinkedIn , \ud83d\ude1d Reddit and \ud83d\udcf1 Telegram . \ud83d\udc8c The best way to contact me is to mention @AlejandroPiad on Twitter. I follow very few people (only those with whom I interact frequently) but I try to reply whenever someone asks me to. And these are the values I stand for: \u2764\ufe0f I believe that people are generally good, and if given the chance, they will show the better parts of themselves. \u2764\ufe0f I believe people should have the chance to speak their minds, without fear to be silenced or hated for it, even if they are wrong. And they should have the option to honestly recognize their mistakes, learn from them, and be forgiven. \u2764\ufe0f I do not tolerate racism or discrimination of any kind, towards me or others around me, and I work very hard to apply those same standards to myself. \u2764\ufe0f I'm dedicated to education because I think that access to high-quality, unbiased, and free education is one of the best gifts anyone can receive, and one of the easiest ways to make people more reasonable and tolerant. \u2764\ufe0f I've been lucky to receive lots of great education from a lot of awesome teachers, to whom I'll be forever grateful. For these reasons, I share what I know for free, in the hopes someone can find it useful. \u2615 If you think what I do is valuable and want to show some love, you can buy me a coffee . It'll make my day!","title":"\u2b50 Home"},{"location":"#hi-there","text":"My name is \ud83d\udc68Alejandro Piad Morffis. Here are some things about me: I live in Havana, \ud83c\udde8\ud83c\uddfaCuba, but I'm temporally located in Alicante, \ud83c\uddea\ud83c\uddf8Spain. I'm currently finishing a \ud83c\udf93PhD in Computer Science. In my free time, I also enjoy \ud83d\udcbb coding (mostly in \ud83d\udc0dPython), \ud83c\udfaeplaying video games (sadly not much lately), and \u270f\ufe0f writing . My two passions are \ud83d\udcdateaching and \u2697\ufe0f researching . I teach Programming, Compilers, AI, and a bunch of other stuff at the University of Havana. I also do research there, mostly on how to use artificial intelligence to better understand human languages. You can find me online on \ud83d\udde8\ufe0f Twitter , \ud83d\udcbc LinkedIn , \ud83d\ude1d Reddit and \ud83d\udcf1 Telegram . \ud83d\udc8c The best way to contact me is to mention @AlejandroPiad on Twitter. I follow very few people (only those with whom I interact frequently) but I try to reply whenever someone asks me to. And these are the values I stand for: \u2764\ufe0f I believe that people are generally good, and if given the chance, they will show the better parts of themselves. \u2764\ufe0f I believe people should have the chance to speak their minds, without fear to be silenced or hated for it, even if they are wrong. And they should have the option to honestly recognize their mistakes, learn from them, and be forgiven. \u2764\ufe0f I do not tolerate racism or discrimination of any kind, towards me or others around me, and I work very hard to apply those same standards to myself. \u2764\ufe0f I'm dedicated to education because I think that access to high-quality, unbiased, and free education is one of the best gifts anyone can receive, and one of the easiest ways to make people more reasonable and tolerant. \u2764\ufe0f I've been lucky to receive lots of great education from a lot of awesome teachers, to whom I'll be forever grateful. For these reasons, I share what I know for free, in the hopes someone can find it useful. \u2615 If you think what I do is valuable and want to show some love, you can buy me a coffee . It'll make my day!","title":"Hi there \ud83d\udd96!"},{"location":"about/projects/","text":"Here are some of the most interesting projects I'm working on: Using the amazing github-readme-stats AutoGOAL \u00b6 \ud83d\udde8\ufe0f Ask me on Twitter. AutoGOAL is a Python framework for Automated Machine Learning that I and a few other colleagues are building. It's the main research result of my wife's Ph.D. , and it is a team project in which I'm a proud contributor and evangelist. Auditorium \u00b6 \ud83d\udde8\ufe0f Ask me on Twitter. Auditorium is my attempt to bring together Python with HTML for interactive slideshows. It is based on reveal.js and allows creating a slideshow with pure Python code, including some interactive stuff like rendering graphs on the fly and running animations. Illiterate \u00b6 \ud83d\udde8\ufe0f Ask me on Twitter. Illiterate is my take at the dilemma of code comments vs documentation. The idea stems from my love for the Literate Programming paradigm with a pragmatic twist that doesn't require any external tooling but rather relies on discipline and conventions.","title":"\ud83d\udcbb Projects"},{"location":"about/projects/#autogoal","text":"\ud83d\udde8\ufe0f Ask me on Twitter. AutoGOAL is a Python framework for Automated Machine Learning that I and a few other colleagues are building. It's the main research result of my wife's Ph.D. , and it is a team project in which I'm a proud contributor and evangelist.","title":"AutoGOAL"},{"location":"about/projects/#auditorium","text":"\ud83d\udde8\ufe0f Ask me on Twitter. Auditorium is my attempt to bring together Python with HTML for interactive slideshows. It is based on reveal.js and allows creating a slideshow with pure Python code, including some interactive stuff like rendering graphs on the fly and running animations.","title":"Auditorium"},{"location":"about/projects/#illiterate","text":"\ud83d\udde8\ufe0f Ask me on Twitter. Illiterate is my take at the dilemma of code comments vs documentation. The idea stems from my love for the Literate Programming paradigm with a pragmatic twist that doesn't require any external tooling but rather relies on discipline and conventions.","title":"Illiterate"},{"location":"about/research/","text":"","title":"\u2697\ufe0f Research"},{"location":"essays/","text":"This is a collection of some things I've written over the years. Instead of blog posts, I consider them kind of short essays. These are varied in format and content, some are more technical, some are more philosophical, others a bit more pragmatic. I honestly don't like to write tutorial-like articles. I've tried a bunch of times and I've failed (though I might try again in the future). For now, I think there are enough amazing people out there doing it much better than I. Hence, these short essays are not about specific technologies or how-to guides. I try to select topics I'm passionate about and that I think have a chance to remain relevant for a longer time. If there is a particular topic you think I might have something interesting to say about, feel free to contact me on Twitter . I've also recently started to post short, actionable stuff in the form of tweetstorm . These are threads of 10-20 tweets that I'm also collecting here for future reference.","title":"\u2753 About essays"},{"location":"essays/academia-oss/","text":"What Academia can learn from Open Source \u00b6 I'm an academic. I love doing research and writing papers. What I don't love is playing the publishing game and waste my time micro-managing all these bureaucratic aspects of academia. I also love open-source software, and while the FOSS community is far from perfect, there are some ideas I think Academia could borrow that would make it more inclusive for everyone and more useful for society. \u26a0\ufe0f This is a rant about some things I think are wrong in Academia and some ideas about how to improve this situation. I mostly focus on Artificial Intelligence because that's my field, but I think most of these ideas apply everywhere. I'm not trying to discredit or criticize any individual or organization, but rather raise some questions that I think all of us scientists, as a community, should attend. I declare myself as guilty of all the sins I describe. \ud83d\uddde\ufe0f The setup \u00b6 If you've ever tried Academia you have surely been in this situation. You come up with a good idea, do some experiments, write a paper about it and... that's when the real work starts. Whether you send that paper to a conference or a journal, you'll get 2 to 5 reviewers to critic your paper, ask you for improvements and decide if your work is good enough for publication. If it's a conference, you'll usually either get accepted or rejected, but if it's a journal, you might get a second chance to improve and resubmit. This process is called peer review , and it's one of the fundamental pillars of Science. Don't get me wrong, peer review is extremely important. You see, Science is a social process. Yes, you can follow the scientific method and come up with a Frankenstein monster all by yourself on a private island, and you would be doing science (without capital \"s\"). It is only when those results are scrutinized, retested, and confirmed by additional researchers, that they become part of the continuous and incremental body of accumulated knowledge that we call Science. Peer review is a fundamental part of this process because it ensures that you are not deluding yourself into believing what you want to believe. It also guarantees we all follow the same high standards of openness, honesty, and goodwill. However, problems arise when the means become an end in itself. Since peer review is such an important concept in Science, we have built all our social scientific processes around it. We set deadlines, ratings, whole systems to formalize and organize what peer review means. We have double-blind and single-blind peer review to guarantee that authors and reviewers don't take revenge on each other. We have evaluation forms and protocols, and we have workshops and workshops about peer review. And yet, time and time again, experiments have shown that reviews are significantly inconsistent. If you randomly redistribute the papers on a top AI conference, a large part of the accepted papers get rejected, and vice-versa. However, I do not take this as evidence that scientists are lousy reviewers. Not even close. Scientists are pretty good at being objectively critical of other's and our work, we do that every single day! I think the problem lies in the system and the incentives built around it, mostly for the benefit of the big players in the Academic world, the publishers. \ud83e\udd15 The symptoms \u00b6 Every time you take a metric and turn it into an objective, it ceases to be a useful metric. This has happened in Science with the concept of publishing a paper . Publishing a paper is the main mechanism for socializing research. A research paper usually describes some scientific hypotheses in as clear terms as possible, a protocol to test (i.e., falsify) those hypotheses, and an honest and critical discussion of results and their implications. By reading a paper, fellow scientists can come up with additional hypotheses or ideas, and build on top of previous work. And every time you use someone else's ideas as part of your own, you are supposed to include a citation. This is what Newton was referring to when he said he had \"stand on the should of giants\". In time, the most significant scientific discoveries should get a large number of citations, because everyone building on top of your ideas would cite you. Hence, a large number of citations is seen as a sign of scientific achievement, and that is often taken as the One Metric of Academic Success . See the problem here? Once citations become a distinction mark, everyone tries to maximize them. A lot of strategies begin to arise, like publishing lots of low-effort papers instead of fewer and better ones, and working only on the most fashionable topics. Since to get cited you have to get published first, publishers become the gatekeepers. A feedback loop starts to build in which publishers try to be as exclusive as possible to attract better papers, since more citations imply more readers which implies more subscriptions; and authors try to aim for the most exclusive publishers since, otherwise, they won't get enough citations. In this dynamic, two very harmful things start to happen. \ud83c\udd70\ufe0f First, scientists spend a lot of effort and money, very often public money, on research that never gets published because of the massive competition. Ironically, once that research made with public money is published, is often put behind a subscription paywall, which most universities and institutions subscribe to. So taxpayers end up paying for research twice, once when done by Alice and again when Bob wants to read Alice's paper. Isn't that crazy enough? \ud83c\udd71\ufe0f The second issue is more subtle but far more harmful. In this process of out-competing each other for citations, we forgot what's important about Science. It's a social process designed to improve human life by solving humanity's most pressing problems. But this competition, far from what free-market ideologists could believe, only serves to undermine the very purpose of Science: \ud83d\udc4e The most fashionable topics get the most attention, and those are often not correlated with the need of the many. \ud83d\udc4e Also, scientists are not born, they are educated. If competition is so fierce that junior researchers don't get a break, we end up losing the best minds before they get a chance to shine. \ud83d\udc4e And finally, this constant competition for citations discourages any kind of self-critic research, any analysis of negative results, and any replication study, because no one will cite you for saying \" yeah, I retested this, and it does seem to work as they originally said... \". This discussion started with peer review, and how the whole academic publishing is built around this concept. Now is the time to criticize it. Since scientists are forced to compete for attention, we have turned peer review from the supportive and self-healing process it should be into the most unpleasant part of doing research. To be fair, not all reviewers are nasty, and when we do, I'm arguing is more often than not because we are forced by the system. \u2b50 The new paradigm \u00b6 I believe the root of the problem in this picture should be clear by now. \u26a0\ufe0f The incentives for scientists are not aligned with the purpose of Science. So, how do we realign the incentives of scientists with the original purpose of Science, and make it better for everyone? Honestly, I don't know. But I think we can take some ideas from the FOSS community to at least foster some good practices which I believe might put us on the right track. The idea starts with embracing Openness in the whole process of scientific discovery and innovation. This is not my original idea, of course, there are some commonly shared principles of \"open science\" in the academic community. This is one possible way to express them: Open Methodology : Document the application of methods and the entire process behind them as far as practicable and relevant. Open Source : Use open source technology (software and hardware) and open your own technologies. Open Data : Make the data freely and easily available. Open Access : Publish openly and make publications usable and accessible to everyone. Open Peer Review : Provide peer review in an open and public forum. Open Educational Resources : Use free and open materials for education and in university teaching. In this form, these principles are quite abstract, and there are many ways in which they could be implemented. There are plenty of degrees of \"open science\" like publishing in open access journals managed by non-profit organizations, publishing pre-prints before submitting to \"traditional\" journals, and all the good practices around making data and protocols publicly available. I want to focus on some key ideas I think could be fruitful to try, without implying that this is the absolute solution to this problem, but rather a small part of a much larger paradigm shift that Science has to undertake. \u2699\ufe0f The practices \u00b6 These are my proposals. Most of them relate specifically to the peer-review process because, as I said before, this process is a pillar of the scientific process, but also because I think this is the one place where we as a community can innovate the most, without requiring government grants or changing the way bureaucratic institutions work. The peer-review process is at the base of the entire scientific process and any major change in its functioning could have a massive impact up the chain. 1\ufe0f\u20e3 Public reviews \u00b6 Let's start by acknowledging that single- and double-blind reviews are more harmful than helpful. These measures are supposed to shield reviewers and authors from future retaliation and disallow any form of favouritism, which should make the review process more just and honest. In practice, they shield reviewers from criticism and make the whole review process less transparent. I propose to turn this concept around and make all reviews completely public. We have to trust we are all reasonable individuals and professional scientists, who should be able to provide objective judgment without favouritism. But if we don't, then our reviews themselves are public, and subject to review and criticism. \ud83d\udc49 This is very easy to implement with any workflow that allows posting comments on a public forum. Note that I don't necessarily mean that anyone can review (this is discussed further down) but even if only specific \"official\" reviewers are assigned to a paper, their comments and their identity and credentials should be public. 2\ufe0f\u20e3 Continuous peer-review \u00b6 This idea ties in with the previous point. Currently, almost all peer-review (that I'm aware of) happens in the context of some specific conference or journal. What I'm proposing here is to detach the peer-review process from any journal or conference and make it instead integral to the paper. Every paper would carry around the Internet with all its reviews, and if rejected at some previous point, a future conference or journal editor would have access to the full history of reviews and changes to reconsider the paper for \"mainstream\" publication (we'll talk more about what this means later). \ud83d\udc49 I can see this happening similar to how issues are handled in Github. You publish a paper, and potential reviewers would open \"issues\" against it, one for each important thing to address. Issues would be discussed and worked on in public and there would a history of every change introduced into the paper with links to which issues are being fixed. Since no paper is perfect, conferences and journal editors should not aim for publishing issue-free papers, but rather papers that show a healthy list of open and closed issues and demonstrable usefulness in their current state. A healthy list of open and closed issues would be an indication of a solid paper, the same way as for software. 3\ufe0f\u20e3 Encouraging reviews \u00b6 The next problem I want to tackle consists of how to kick-start the reviewing process. Once we detach reviews from specific conferences or journals, how can we guarantee everyone has access to good reviews? For sure, rockstar scientists will get thousands of reviews but what about junior researchers who are just starting? One idea is to see reviewing as an integral part of the scientific career. Researchers should be evaluated also in terms of how much value they put back to the community, and one way senior scientists can contribute is to review junior scientists. We should be proud to put in our CVs how many reviews we have given. And good reviews, which are in turn evaluated positively by the author and other reviewers, should count towards one's scientific output. \ud83d\udc49 Scientists would get a \"badge\" with the number reviews they have given, and display it on their homepage, their LinkedIn or ResearchGate profile, etc. This badge would link to some online list that links back to all reviews. This could be maybe hosted our ORCID profiles or any similar non-profit initiative. Also, senior researchers are part of a community, and are often connected with like-minded individuals in other institutions and countries. It should be part of their work to look up for each other's students and junior researchers. And yes, someone will say \" but then you can give a good review to my students if I give a good review to yours \". Again, this is why all review is, first and foremost, public in nature. 4\ufe0f\u20e3 Qualitative evaluations \u00b6 Now let's move on to specific review formats. Too often I see very long lists of checkboxes and 1-5 ratings, etc. I believe there is value in having a structured evaluation template, to make sure we more or less agree on what are the core issues we should care about. But going to the extreme of having 10 different ratings for a paper is insane! What is the difference between 6 and 7? When putting reviewers under the pressure of giving numerical scores, we are asking them to unconsciously introduce all the biases they have about that particular problem or field or approach or author. There is simply no objective way to numerically compare two different papers. A good research paper needs to have a solid methodology (correctly apply the principles of science as it is common practice in that field), provide relevant results and conclusions (either positive or negative), be feasible to reproduce by independent researchers, and have a clear presentation. Either the paper is good enough to be considered publishable, if all these aspects are covered, or it isn't. That's it. \ud83d\udc49 I prefer a simple evaluation form that asks: \" Is this aspect of the paper up to the scientific standard? , and a piece of free-form text for you to explain what is lacking in each aspect. Methodology [x] \ud83d\udc4d [ ] \ud83d\udc4e Results [x] \ud83d\udc4d [ ] \ud83d\udc4e Reproducibility [ ] \ud83d\udc4d [x] \ud83d\udc4e Presentation [ ] \ud83d\udc4d [x] \ud83d\udc4e A specific conference or journal might want to evaluate the potential impact or significance of a paper before accepting it for publishing. But impact or significance is not what Science is about. There are however legitimate cases where impact or significance is important. If you have to allocate a restricted pool of resources (e.g., grant money) of course you want to evaluate impact. Yet, I argue this is not part of the peer-review process, but a posterior analysis that each institution or publisher should do based on their specific criteria. Peer-review should be a process by which the scientific community as a whole evaluates that some research is sound science, irrespective of idiosyncrasies. 5\ufe0f\u20e3 Self-publishing \u00b6 Now that the peer-review process is completely detached from the \"mainstream\" publishing industry, who decides when is a paper ready to be published? Well, of course, the authors! It is up to the authors to determine that, given all the feedback received, they consider their work is production-ready. \ud83d\udc49 All papers would be published first in draft-mode, perhaps even before being completely written. During the draft phase, you collect all the feedback you can from peer reviews and work on the issues you consider more relevant. When you feel it is good enough (possibly because most of the recent reviews are favourable) you hit that Publish button and create a release. If some errors appear, later on, you fix them and publish another release. \ud83d\udc49 What becomes citable then? Easy, each release of each paper gets a unique DOI that will forever point to that exact version, together with all its metadata and reviews. If I cite something yours and criticize it, and you later fix it, that's OK. My critic is still valid because it points to a previous version that is indexable, and the fact that you fixed it only speaks higher of you! But wait, won't authors publish a lot of low-effort papers to engross their CVs? Well, maybe someone will but, who cares? We started by saying that, intuitively, citations should be a good measure of scientific quality. This is still true in this format. If I release a bunch of crappy papers, no one will cite them. And also, who thinks CVs are useful? Anyone trying to evaluate me as a researcher would not look into some list of titles and numbers I pasted in a Word document. They would go to my researcher profile and see my most significant work, the reviews it has received, and how my whole research process works! This doesn't mean that I get to decide my work is relevant, however. This just means I get to decide my work is ready to be consumed by the scientific community. The community will still judge my work's relevance by citing it, criticizing it, and in two more ways I left for the end. 6\ufe0f\u20e3 Conferences for networking \u00b6 Now that all papers are being published by their authors, what's the purpose of scientific conferences? We can now recover their original purpose. Conferences were created as a medium to get like-minded scientists together to share their experiences and to discuss the most relevant problems of their field. But as conferences became more and more a mainstream path for getting published, their organization has become more and more about managing the peer-review process. Now that peer-review is detached from conferences, their organizers are free to focus on scooping what are the most interesting topics and the most significant results in those topics and invite those speakers they believe will the bring the biggest value. Which papers get to be presented? I think we could deal with that in two ways: \ud83d\udc49 As an organizer of a thematic conference, I would spend half of the year looking around for interesting papers to invite their authors. They would still pay for their accommodations (or their institutions would) and they would come to enjoy what's best in every conference, the networking. \ud83d\udc49 I could also open a call for papers, as usual, but authors would submit papers that are already reviewed and released. My role would be to decide, based primarily on thematic fit, what I think is more relevant for my community. \ud83d\udc49 There is even no need to attach participation to a published paper. Authors could simply submit \"talks\", possibly backed by one or more papers that support their submission, as it is already common in some conferences. This would completely reshape what conferences are for (at least in my field). There is no reason why we should wait to the top conferences of the year to be able to read papers. We would go to conferences for the chance to talk with the researchers we admire about their work. And someone asks, but how would conferences compete if they have no publication rights? Well, I argue this would be very good. Conference organizers would have to compete on the grounds of providing a better environment for networking, interesting events, nice amenities, but no one would have a monopoly on the knowledge itself. There is even no reason why the same talk cannot be presented in more than one conference if enough people are willing to listen. 7\ufe0f\u20e3 Journals for socializing \u00b6 And finally we come round to the original culprit, the infamous research journal. Now that papers are published openly, what are journals good for? Well, what they were originally designed for, socializing research! Journals were created as a means for academic societies to collect the most relevant research in a given community and publish it for a larger audience. Then commercial publishers arrived and turned science into a business, and journals became paywalled gatekeepers of knowledge, that require original research often paid with public money that they resell again for public money. The largest academic publishers often state they have costs to cover, but there is plenty of evidence that they make a significant profit. And that's OK, but if I as a journal editor want to make a profit, I'm gonna have to innovate. \ud83d\udc49 Like conferences, I could scoop around and feature the most interesting papers in some thematic issues, maybe ask the authors to give some new comments on them, prepare explainer videos, add links, and put some effort into turning those \"raw\" papers into beautifully typeset pages. \ud83d\udc49 SOTA reviews would be a nice fit for journals as well. These are not original research papers, but they often provide a lot of value by analyzing a bunch of papers and giving advice on common trends or highlighting interesting lines for future research. \ud83d\udc49 I would also have editorial articles specifically written for an issue that could summarize in layman terms about a particular subject, to introduce it to a larger audience. I would even pay scientists that are good communicators for this work. Journals would have to compete on the grounds of being good at selecting topics and papers to socialize, and provide some additional editorial value. In any case, original research papers would be owned only by their authors and would be published always with some public license (e.g., Creative Commons). This would ensure that Science belongs to the ones who ultimately pay for it, that is, society. \ud83d\udcbb The system \u00b6 Putting all these ideas together in a functioning system will require a lot of work. From the infrastructure point of view, I envision something aking Github, a repository of open access papers with builtin comments, reviewing, and social features. Ideally, it would also have a web UI for editing, similar to Overleaf and, of course, fully integrated with Git. I understand this might not be the best solution for academic communities that are not very closely related to software, i.e., social sciences, mostly because it could pose a significant learning curve for their members and become more of a hinder than a help. From the social point of view, kick-starting such a system would require a massive community effort. And not because of the infrastructure cost, that's the minor issue. I think the largest obstacle for this kind of paradigm shift is that a large part of the community would have to move away simultaneously from journals and conferences as the main publication channels. Otherwise, the few that start the effort will be completely disconnected from the rest of the community. I can see this happening as an effort from, say, the AI community, or any other technically-savvy collective. Tomorrow morning, all the senior scientists that publish in ICLR, ICML, NeurIPs, and ACL, could suddenly decide they want to go fully open. It would require the conference organizers to support the initiative as well. Instead of opening a call for papers, the conferences could decide that they would open a call for submissions, which should peer-reviewed and published in this new format. Some non-profit organization could be formed from within the community to provide the infrastructure. Since there will be some operative costs, this platform would require some payment, but it would be very small compared to publishing fees in most major open access journals. Also, some of the big players in the industry could support this initiative by providing hosting and infrastructure for free. This would be a big PR boost to these companies. \ud83d\udcca The metrics \u00b6 We started this discussion by saying that an intuitively good metric to estimate scientific impact, i.e., citations, had become an objective and thus lost their entire meaning. But citations are not an inherently bad metric, it's just when we use citations as the one quantitative metric to compare individual researchers that we miss the entire point. Likewise, the fact that we self-publish all our papers doesn't mean that being featured in a major conference or journal is worthless. On the contrary, when everything we publish is open, being featured in a mainstream publication becomes an even better measure of impact, because it is no longer tied to my financial capacity or any other unfair advantage I might enjoy in the community. This would be very good for Third World researchers, who produce valuable science, but are often cutoff from mainstream publication for reasons completely unrelated to the quality of the research. If we can restructure the incentives and processes of Science such that they are aligned with the purpose of Science as primarily a means to improve human life, everything else would fall into place. Once researchers are free from predatory publishing practices, meaningless numerical statistics and unhealthy competition, I believe we will all focus what we love most, doing sound research for the good of mankind. Then, all those metrics that are used today will regain their meaning. Being invited to a top-tier conference would mean that what your community wants to hear from you. Being featured in a top-tier journal would mean that some editors consider your work is high-quality. And being cited often would mean that your research is producing real impact, that you are becoming a giant on whose shoulders others can stand. \ud83d\udde8\ufe0f This is a topic of which I'm very passionate about, and I want to hear your feedback. If you want to discuss this topic with me, give me a shout in Twitter . \ud83d\udeab If you find some typo, error or you have any suggestion to help me improve this page, you can suggest and edit or open an issue in Github .","title":"Academia & OSS"},{"location":"essays/academia-oss/#what-academia-can-learn-from-open-source","text":"I'm an academic. I love doing research and writing papers. What I don't love is playing the publishing game and waste my time micro-managing all these bureaucratic aspects of academia. I also love open-source software, and while the FOSS community is far from perfect, there are some ideas I think Academia could borrow that would make it more inclusive for everyone and more useful for society. \u26a0\ufe0f This is a rant about some things I think are wrong in Academia and some ideas about how to improve this situation. I mostly focus on Artificial Intelligence because that's my field, but I think most of these ideas apply everywhere. I'm not trying to discredit or criticize any individual or organization, but rather raise some questions that I think all of us scientists, as a community, should attend. I declare myself as guilty of all the sins I describe.","title":"What Academia can learn from Open Source"},{"location":"essays/academia-oss/#the-setup","text":"If you've ever tried Academia you have surely been in this situation. You come up with a good idea, do some experiments, write a paper about it and... that's when the real work starts. Whether you send that paper to a conference or a journal, you'll get 2 to 5 reviewers to critic your paper, ask you for improvements and decide if your work is good enough for publication. If it's a conference, you'll usually either get accepted or rejected, but if it's a journal, you might get a second chance to improve and resubmit. This process is called peer review , and it's one of the fundamental pillars of Science. Don't get me wrong, peer review is extremely important. You see, Science is a social process. Yes, you can follow the scientific method and come up with a Frankenstein monster all by yourself on a private island, and you would be doing science (without capital \"s\"). It is only when those results are scrutinized, retested, and confirmed by additional researchers, that they become part of the continuous and incremental body of accumulated knowledge that we call Science. Peer review is a fundamental part of this process because it ensures that you are not deluding yourself into believing what you want to believe. It also guarantees we all follow the same high standards of openness, honesty, and goodwill. However, problems arise when the means become an end in itself. Since peer review is such an important concept in Science, we have built all our social scientific processes around it. We set deadlines, ratings, whole systems to formalize and organize what peer review means. We have double-blind and single-blind peer review to guarantee that authors and reviewers don't take revenge on each other. We have evaluation forms and protocols, and we have workshops and workshops about peer review. And yet, time and time again, experiments have shown that reviews are significantly inconsistent. If you randomly redistribute the papers on a top AI conference, a large part of the accepted papers get rejected, and vice-versa. However, I do not take this as evidence that scientists are lousy reviewers. Not even close. Scientists are pretty good at being objectively critical of other's and our work, we do that every single day! I think the problem lies in the system and the incentives built around it, mostly for the benefit of the big players in the Academic world, the publishers.","title":"\ud83d\uddde\ufe0f The setup"},{"location":"essays/academia-oss/#the-symptoms","text":"Every time you take a metric and turn it into an objective, it ceases to be a useful metric. This has happened in Science with the concept of publishing a paper . Publishing a paper is the main mechanism for socializing research. A research paper usually describes some scientific hypotheses in as clear terms as possible, a protocol to test (i.e., falsify) those hypotheses, and an honest and critical discussion of results and their implications. By reading a paper, fellow scientists can come up with additional hypotheses or ideas, and build on top of previous work. And every time you use someone else's ideas as part of your own, you are supposed to include a citation. This is what Newton was referring to when he said he had \"stand on the should of giants\". In time, the most significant scientific discoveries should get a large number of citations, because everyone building on top of your ideas would cite you. Hence, a large number of citations is seen as a sign of scientific achievement, and that is often taken as the One Metric of Academic Success . See the problem here? Once citations become a distinction mark, everyone tries to maximize them. A lot of strategies begin to arise, like publishing lots of low-effort papers instead of fewer and better ones, and working only on the most fashionable topics. Since to get cited you have to get published first, publishers become the gatekeepers. A feedback loop starts to build in which publishers try to be as exclusive as possible to attract better papers, since more citations imply more readers which implies more subscriptions; and authors try to aim for the most exclusive publishers since, otherwise, they won't get enough citations. In this dynamic, two very harmful things start to happen. \ud83c\udd70\ufe0f First, scientists spend a lot of effort and money, very often public money, on research that never gets published because of the massive competition. Ironically, once that research made with public money is published, is often put behind a subscription paywall, which most universities and institutions subscribe to. So taxpayers end up paying for research twice, once when done by Alice and again when Bob wants to read Alice's paper. Isn't that crazy enough? \ud83c\udd71\ufe0f The second issue is more subtle but far more harmful. In this process of out-competing each other for citations, we forgot what's important about Science. It's a social process designed to improve human life by solving humanity's most pressing problems. But this competition, far from what free-market ideologists could believe, only serves to undermine the very purpose of Science: \ud83d\udc4e The most fashionable topics get the most attention, and those are often not correlated with the need of the many. \ud83d\udc4e Also, scientists are not born, they are educated. If competition is so fierce that junior researchers don't get a break, we end up losing the best minds before they get a chance to shine. \ud83d\udc4e And finally, this constant competition for citations discourages any kind of self-critic research, any analysis of negative results, and any replication study, because no one will cite you for saying \" yeah, I retested this, and it does seem to work as they originally said... \". This discussion started with peer review, and how the whole academic publishing is built around this concept. Now is the time to criticize it. Since scientists are forced to compete for attention, we have turned peer review from the supportive and self-healing process it should be into the most unpleasant part of doing research. To be fair, not all reviewers are nasty, and when we do, I'm arguing is more often than not because we are forced by the system.","title":"\ud83e\udd15 The symptoms"},{"location":"essays/academia-oss/#the-new-paradigm","text":"I believe the root of the problem in this picture should be clear by now. \u26a0\ufe0f The incentives for scientists are not aligned with the purpose of Science. So, how do we realign the incentives of scientists with the original purpose of Science, and make it better for everyone? Honestly, I don't know. But I think we can take some ideas from the FOSS community to at least foster some good practices which I believe might put us on the right track. The idea starts with embracing Openness in the whole process of scientific discovery and innovation. This is not my original idea, of course, there are some commonly shared principles of \"open science\" in the academic community. This is one possible way to express them: Open Methodology : Document the application of methods and the entire process behind them as far as practicable and relevant. Open Source : Use open source technology (software and hardware) and open your own technologies. Open Data : Make the data freely and easily available. Open Access : Publish openly and make publications usable and accessible to everyone. Open Peer Review : Provide peer review in an open and public forum. Open Educational Resources : Use free and open materials for education and in university teaching. In this form, these principles are quite abstract, and there are many ways in which they could be implemented. There are plenty of degrees of \"open science\" like publishing in open access journals managed by non-profit organizations, publishing pre-prints before submitting to \"traditional\" journals, and all the good practices around making data and protocols publicly available. I want to focus on some key ideas I think could be fruitful to try, without implying that this is the absolute solution to this problem, but rather a small part of a much larger paradigm shift that Science has to undertake.","title":"\u2b50 The new paradigm"},{"location":"essays/academia-oss/#the-practices","text":"These are my proposals. Most of them relate specifically to the peer-review process because, as I said before, this process is a pillar of the scientific process, but also because I think this is the one place where we as a community can innovate the most, without requiring government grants or changing the way bureaucratic institutions work. The peer-review process is at the base of the entire scientific process and any major change in its functioning could have a massive impact up the chain.","title":"\u2699\ufe0f The practices"},{"location":"essays/academia-oss/#1-public-reviews","text":"Let's start by acknowledging that single- and double-blind reviews are more harmful than helpful. These measures are supposed to shield reviewers and authors from future retaliation and disallow any form of favouritism, which should make the review process more just and honest. In practice, they shield reviewers from criticism and make the whole review process less transparent. I propose to turn this concept around and make all reviews completely public. We have to trust we are all reasonable individuals and professional scientists, who should be able to provide objective judgment without favouritism. But if we don't, then our reviews themselves are public, and subject to review and criticism. \ud83d\udc49 This is very easy to implement with any workflow that allows posting comments on a public forum. Note that I don't necessarily mean that anyone can review (this is discussed further down) but even if only specific \"official\" reviewers are assigned to a paper, their comments and their identity and credentials should be public.","title":"1\ufe0f\u20e3 Public reviews"},{"location":"essays/academia-oss/#2-continuous-peer-review","text":"This idea ties in with the previous point. Currently, almost all peer-review (that I'm aware of) happens in the context of some specific conference or journal. What I'm proposing here is to detach the peer-review process from any journal or conference and make it instead integral to the paper. Every paper would carry around the Internet with all its reviews, and if rejected at some previous point, a future conference or journal editor would have access to the full history of reviews and changes to reconsider the paper for \"mainstream\" publication (we'll talk more about what this means later). \ud83d\udc49 I can see this happening similar to how issues are handled in Github. You publish a paper, and potential reviewers would open \"issues\" against it, one for each important thing to address. Issues would be discussed and worked on in public and there would a history of every change introduced into the paper with links to which issues are being fixed. Since no paper is perfect, conferences and journal editors should not aim for publishing issue-free papers, but rather papers that show a healthy list of open and closed issues and demonstrable usefulness in their current state. A healthy list of open and closed issues would be an indication of a solid paper, the same way as for software.","title":"2\ufe0f\u20e3 Continuous peer-review"},{"location":"essays/academia-oss/#3-encouraging-reviews","text":"The next problem I want to tackle consists of how to kick-start the reviewing process. Once we detach reviews from specific conferences or journals, how can we guarantee everyone has access to good reviews? For sure, rockstar scientists will get thousands of reviews but what about junior researchers who are just starting? One idea is to see reviewing as an integral part of the scientific career. Researchers should be evaluated also in terms of how much value they put back to the community, and one way senior scientists can contribute is to review junior scientists. We should be proud to put in our CVs how many reviews we have given. And good reviews, which are in turn evaluated positively by the author and other reviewers, should count towards one's scientific output. \ud83d\udc49 Scientists would get a \"badge\" with the number reviews they have given, and display it on their homepage, their LinkedIn or ResearchGate profile, etc. This badge would link to some online list that links back to all reviews. This could be maybe hosted our ORCID profiles or any similar non-profit initiative. Also, senior researchers are part of a community, and are often connected with like-minded individuals in other institutions and countries. It should be part of their work to look up for each other's students and junior researchers. And yes, someone will say \" but then you can give a good review to my students if I give a good review to yours \". Again, this is why all review is, first and foremost, public in nature.","title":"3\ufe0f\u20e3 Encouraging reviews"},{"location":"essays/academia-oss/#4-qualitative-evaluations","text":"Now let's move on to specific review formats. Too often I see very long lists of checkboxes and 1-5 ratings, etc. I believe there is value in having a structured evaluation template, to make sure we more or less agree on what are the core issues we should care about. But going to the extreme of having 10 different ratings for a paper is insane! What is the difference between 6 and 7? When putting reviewers under the pressure of giving numerical scores, we are asking them to unconsciously introduce all the biases they have about that particular problem or field or approach or author. There is simply no objective way to numerically compare two different papers. A good research paper needs to have a solid methodology (correctly apply the principles of science as it is common practice in that field), provide relevant results and conclusions (either positive or negative), be feasible to reproduce by independent researchers, and have a clear presentation. Either the paper is good enough to be considered publishable, if all these aspects are covered, or it isn't. That's it. \ud83d\udc49 I prefer a simple evaluation form that asks: \" Is this aspect of the paper up to the scientific standard? , and a piece of free-form text for you to explain what is lacking in each aspect. Methodology [x] \ud83d\udc4d [ ] \ud83d\udc4e Results [x] \ud83d\udc4d [ ] \ud83d\udc4e Reproducibility [ ] \ud83d\udc4d [x] \ud83d\udc4e Presentation [ ] \ud83d\udc4d [x] \ud83d\udc4e A specific conference or journal might want to evaluate the potential impact or significance of a paper before accepting it for publishing. But impact or significance is not what Science is about. There are however legitimate cases where impact or significance is important. If you have to allocate a restricted pool of resources (e.g., grant money) of course you want to evaluate impact. Yet, I argue this is not part of the peer-review process, but a posterior analysis that each institution or publisher should do based on their specific criteria. Peer-review should be a process by which the scientific community as a whole evaluates that some research is sound science, irrespective of idiosyncrasies.","title":"4\ufe0f\u20e3 Qualitative evaluations"},{"location":"essays/academia-oss/#5-self-publishing","text":"Now that the peer-review process is completely detached from the \"mainstream\" publishing industry, who decides when is a paper ready to be published? Well, of course, the authors! It is up to the authors to determine that, given all the feedback received, they consider their work is production-ready. \ud83d\udc49 All papers would be published first in draft-mode, perhaps even before being completely written. During the draft phase, you collect all the feedback you can from peer reviews and work on the issues you consider more relevant. When you feel it is good enough (possibly because most of the recent reviews are favourable) you hit that Publish button and create a release. If some errors appear, later on, you fix them and publish another release. \ud83d\udc49 What becomes citable then? Easy, each release of each paper gets a unique DOI that will forever point to that exact version, together with all its metadata and reviews. If I cite something yours and criticize it, and you later fix it, that's OK. My critic is still valid because it points to a previous version that is indexable, and the fact that you fixed it only speaks higher of you! But wait, won't authors publish a lot of low-effort papers to engross their CVs? Well, maybe someone will but, who cares? We started by saying that, intuitively, citations should be a good measure of scientific quality. This is still true in this format. If I release a bunch of crappy papers, no one will cite them. And also, who thinks CVs are useful? Anyone trying to evaluate me as a researcher would not look into some list of titles and numbers I pasted in a Word document. They would go to my researcher profile and see my most significant work, the reviews it has received, and how my whole research process works! This doesn't mean that I get to decide my work is relevant, however. This just means I get to decide my work is ready to be consumed by the scientific community. The community will still judge my work's relevance by citing it, criticizing it, and in two more ways I left for the end.","title":"5\ufe0f\u20e3 Self-publishing"},{"location":"essays/academia-oss/#6-conferences-for-networking","text":"Now that all papers are being published by their authors, what's the purpose of scientific conferences? We can now recover their original purpose. Conferences were created as a medium to get like-minded scientists together to share their experiences and to discuss the most relevant problems of their field. But as conferences became more and more a mainstream path for getting published, their organization has become more and more about managing the peer-review process. Now that peer-review is detached from conferences, their organizers are free to focus on scooping what are the most interesting topics and the most significant results in those topics and invite those speakers they believe will the bring the biggest value. Which papers get to be presented? I think we could deal with that in two ways: \ud83d\udc49 As an organizer of a thematic conference, I would spend half of the year looking around for interesting papers to invite their authors. They would still pay for their accommodations (or their institutions would) and they would come to enjoy what's best in every conference, the networking. \ud83d\udc49 I could also open a call for papers, as usual, but authors would submit papers that are already reviewed and released. My role would be to decide, based primarily on thematic fit, what I think is more relevant for my community. \ud83d\udc49 There is even no need to attach participation to a published paper. Authors could simply submit \"talks\", possibly backed by one or more papers that support their submission, as it is already common in some conferences. This would completely reshape what conferences are for (at least in my field). There is no reason why we should wait to the top conferences of the year to be able to read papers. We would go to conferences for the chance to talk with the researchers we admire about their work. And someone asks, but how would conferences compete if they have no publication rights? Well, I argue this would be very good. Conference organizers would have to compete on the grounds of providing a better environment for networking, interesting events, nice amenities, but no one would have a monopoly on the knowledge itself. There is even no reason why the same talk cannot be presented in more than one conference if enough people are willing to listen.","title":"6\ufe0f\u20e3 Conferences for networking"},{"location":"essays/academia-oss/#7-journals-for-socializing","text":"And finally we come round to the original culprit, the infamous research journal. Now that papers are published openly, what are journals good for? Well, what they were originally designed for, socializing research! Journals were created as a means for academic societies to collect the most relevant research in a given community and publish it for a larger audience. Then commercial publishers arrived and turned science into a business, and journals became paywalled gatekeepers of knowledge, that require original research often paid with public money that they resell again for public money. The largest academic publishers often state they have costs to cover, but there is plenty of evidence that they make a significant profit. And that's OK, but if I as a journal editor want to make a profit, I'm gonna have to innovate. \ud83d\udc49 Like conferences, I could scoop around and feature the most interesting papers in some thematic issues, maybe ask the authors to give some new comments on them, prepare explainer videos, add links, and put some effort into turning those \"raw\" papers into beautifully typeset pages. \ud83d\udc49 SOTA reviews would be a nice fit for journals as well. These are not original research papers, but they often provide a lot of value by analyzing a bunch of papers and giving advice on common trends or highlighting interesting lines for future research. \ud83d\udc49 I would also have editorial articles specifically written for an issue that could summarize in layman terms about a particular subject, to introduce it to a larger audience. I would even pay scientists that are good communicators for this work. Journals would have to compete on the grounds of being good at selecting topics and papers to socialize, and provide some additional editorial value. In any case, original research papers would be owned only by their authors and would be published always with some public license (e.g., Creative Commons). This would ensure that Science belongs to the ones who ultimately pay for it, that is, society.","title":"7\ufe0f\u20e3 Journals for socializing"},{"location":"essays/academia-oss/#the-system","text":"Putting all these ideas together in a functioning system will require a lot of work. From the infrastructure point of view, I envision something aking Github, a repository of open access papers with builtin comments, reviewing, and social features. Ideally, it would also have a web UI for editing, similar to Overleaf and, of course, fully integrated with Git. I understand this might not be the best solution for academic communities that are not very closely related to software, i.e., social sciences, mostly because it could pose a significant learning curve for their members and become more of a hinder than a help. From the social point of view, kick-starting such a system would require a massive community effort. And not because of the infrastructure cost, that's the minor issue. I think the largest obstacle for this kind of paradigm shift is that a large part of the community would have to move away simultaneously from journals and conferences as the main publication channels. Otherwise, the few that start the effort will be completely disconnected from the rest of the community. I can see this happening as an effort from, say, the AI community, or any other technically-savvy collective. Tomorrow morning, all the senior scientists that publish in ICLR, ICML, NeurIPs, and ACL, could suddenly decide they want to go fully open. It would require the conference organizers to support the initiative as well. Instead of opening a call for papers, the conferences could decide that they would open a call for submissions, which should peer-reviewed and published in this new format. Some non-profit organization could be formed from within the community to provide the infrastructure. Since there will be some operative costs, this platform would require some payment, but it would be very small compared to publishing fees in most major open access journals. Also, some of the big players in the industry could support this initiative by providing hosting and infrastructure for free. This would be a big PR boost to these companies.","title":"\ud83d\udcbb The system"},{"location":"essays/academia-oss/#the-metrics","text":"We started this discussion by saying that an intuitively good metric to estimate scientific impact, i.e., citations, had become an objective and thus lost their entire meaning. But citations are not an inherently bad metric, it's just when we use citations as the one quantitative metric to compare individual researchers that we miss the entire point. Likewise, the fact that we self-publish all our papers doesn't mean that being featured in a major conference or journal is worthless. On the contrary, when everything we publish is open, being featured in a mainstream publication becomes an even better measure of impact, because it is no longer tied to my financial capacity or any other unfair advantage I might enjoy in the community. This would be very good for Third World researchers, who produce valuable science, but are often cutoff from mainstream publication for reasons completely unrelated to the quality of the research. If we can restructure the incentives and processes of Science such that they are aligned with the purpose of Science as primarily a means to improve human life, everything else would fall into place. Once researchers are free from predatory publishing practices, meaningless numerical statistics and unhealthy competition, I believe we will all focus what we love most, doing sound research for the good of mankind. Then, all those metrics that are used today will regain their meaning. Being invited to a top-tier conference would mean that what your community wants to hear from you. Being featured in a top-tier journal would mean that some editors consider your work is high-quality. And being cited often would mean that your research is producing real impact, that you are becoming a giant on whose shoulders others can stand. \ud83d\udde8\ufe0f This is a topic of which I'm very passionate about, and I want to hear your feedback. If you want to discuss this topic with me, give me a shout in Twitter . \ud83d\udeab If you find some typo, error or you have any suggestion to help me improve this page, you can suggest and edit or open an issue in Github .","title":"\ud83d\udcca The metrics"},{"location":"essays/teaching/","text":"Why I love teaching \u00b6 When people ask me who I am, the short answer is \"a teacher\", even though I do a bunch of other stuff. This is why. I didn't know I wanted to be a college teacher until about 3rd year of my major at the University of Havana. Even then, the thought came slowly, something like \"yeah teaching could nice, but if I have to do something completely different, I may as well enjoy that\". By the end of the 5th year (it was a 5-years major back then) I was sure there was nothing else that could fill me up. I've been in front of a classroom for a few years now, at least twice a week one semester a year, ever since my first time back in 2009. And I've loved every minute of it. Students are the same everywhere. They have hopes, dreams, and a lot of misconceptions. They come thinking they want to be something (an engineer, a computer scientist, a journalist, a lawyer, ...), because they think that choice will lead them to do something (solve problems, work at a large company, travel the world, ...). So they focus on that search: what is the something they want to do, hence, the something they want to be? My main task is to try and convince them otherwise. The search is not about a something . It's about a someone . You need to come to college to discover who you want to be, not what you want to be. And if this sounds a bit philosophical (or plain crap), then I'm (un)apologetically sorry. Engineer, computer scientist, lawyer, all of those are just labels that somehow try to average over the set of things that people who label themselves that way like to do. Don't get me wrong, labels are important. They help us organize and understand the world. But if there is one occasion when you don't want a simple label to smooth away all the tiny details, is when choosing (or searching) what you want to do for life, or even better, who you want to be for life. \u2b50 So when people ask me \"are you an engineer, a scientist, or a philosopher?\" I answer yes. I'm mostly a scientist, because I do more research than the average engineer; but I'm also an engineer, because I solve more problems than the average philosopher; and, I'm also a philosopher, because I like to think more about the implications of my decisions than the average scientist. I'm also a lot of other things, if you ask. It's not that I'm somehow \"better\" than any of these individual labels, it's simply that I choose to be my own brew of these \"things\", taking from each what I like and dumping what I don't. To a simple question ( what are you?) I can only give a simple answer (yes). If you want the details, you'll have to ask a deeper question: who are you? My first day in class every year, I like to throw a simple question at my students: who do you want to be? Most of them answer with a combination of whats. I want to be this or I want to do that. Over the year, some start to discover they want to be someone , not just something. They start dumping the labels and start answering to this question not with things (I want to be a programmer) but with choices (I want to solve this specific problem, I want to cure this disease, I want to create this gadget). Those choices become the who they strive for. Eventually, even if unconsciously, most reach this state. A tiny fraction of them will consciously acknowledge it. And an even smaller fraction, maybe one or two a year, sometimes none, will come one day and say to me something like \"thank you for helping me find my who\", even if not with those exact words. And that's it. That small moment when I realize someone found its own best version, and I had a tiny bit of influence. That's all the payment I need. That's why I love teaching. \ud83d\udde8\ufe0f This is a topic of which I'm very passionate about, and I want to hear your feedback. If you want to discuss this topic with me, give me a shout in Twitter . \ud83d\udeab If you find some typo, error or you have any suggestion to help me improve this page, you can suggest and edit or open an issue in Github .","title":"Why I love teaching"},{"location":"essays/teaching/#why-i-love-teaching","text":"When people ask me who I am, the short answer is \"a teacher\", even though I do a bunch of other stuff. This is why. I didn't know I wanted to be a college teacher until about 3rd year of my major at the University of Havana. Even then, the thought came slowly, something like \"yeah teaching could nice, but if I have to do something completely different, I may as well enjoy that\". By the end of the 5th year (it was a 5-years major back then) I was sure there was nothing else that could fill me up. I've been in front of a classroom for a few years now, at least twice a week one semester a year, ever since my first time back in 2009. And I've loved every minute of it. Students are the same everywhere. They have hopes, dreams, and a lot of misconceptions. They come thinking they want to be something (an engineer, a computer scientist, a journalist, a lawyer, ...), because they think that choice will lead them to do something (solve problems, work at a large company, travel the world, ...). So they focus on that search: what is the something they want to do, hence, the something they want to be? My main task is to try and convince them otherwise. The search is not about a something . It's about a someone . You need to come to college to discover who you want to be, not what you want to be. And if this sounds a bit philosophical (or plain crap), then I'm (un)apologetically sorry. Engineer, computer scientist, lawyer, all of those are just labels that somehow try to average over the set of things that people who label themselves that way like to do. Don't get me wrong, labels are important. They help us organize and understand the world. But if there is one occasion when you don't want a simple label to smooth away all the tiny details, is when choosing (or searching) what you want to do for life, or even better, who you want to be for life. \u2b50 So when people ask me \"are you an engineer, a scientist, or a philosopher?\" I answer yes. I'm mostly a scientist, because I do more research than the average engineer; but I'm also an engineer, because I solve more problems than the average philosopher; and, I'm also a philosopher, because I like to think more about the implications of my decisions than the average scientist. I'm also a lot of other things, if you ask. It's not that I'm somehow \"better\" than any of these individual labels, it's simply that I choose to be my own brew of these \"things\", taking from each what I like and dumping what I don't. To a simple question ( what are you?) I can only give a simple answer (yes). If you want the details, you'll have to ask a deeper question: who are you? My first day in class every year, I like to throw a simple question at my students: who do you want to be? Most of them answer with a combination of whats. I want to be this or I want to do that. Over the year, some start to discover they want to be someone , not just something. They start dumping the labels and start answering to this question not with things (I want to be a programmer) but with choices (I want to solve this specific problem, I want to cure this disease, I want to create this gadget). Those choices become the who they strive for. Eventually, even if unconsciously, most reach this state. A tiny fraction of them will consciously acknowledge it. And an even smaller fraction, maybe one or two a year, sometimes none, will come one day and say to me something like \"thank you for helping me find my who\", even if not with those exact words. And that's it. That small moment when I realize someone found its own best version, and I had a tiny bit of influence. That's all the payment I need. That's why I love teaching. \ud83d\udde8\ufe0f This is a topic of which I'm very passionate about, and I want to hear your feedback. If you want to discuss this topic with me, give me a shout in Twitter . \ud83d\udeab If you find some typo, error or you have any suggestion to help me improve this page, you can suggest and edit or open an issue in Github .","title":"Why I love teaching"},{"location":"essays/team-playing/","text":"It's all about team-playing \u00b6 Modern higher education is all about competences and skills. In the process, we are losing some very bright people who just don't fit this narrow-minded model of professionalism. Modern education started with the Industrial Revolution and the need to graduate tons of skilled workers to carry on the same tasks over and over. Previously, education was only for the brightest and/or luckiest, and usually consisted of a very custom path through which a tutor would guide you. Nowadays in universities all around the world, we have reduced students to numbers, grades, percentages, as if we were producing computer chips or combustion engines. Efficiency is all that matters. To achieve the highest possible efficiency, all around the world we educators have become engineers of sorts. We designed what we call a \"model of the professional\", which is a set of skills and competencies that an abstract ideal professional should have. Then we designed an evaluation metric he micro-average of a ton of super-narrow scores that measure super-specific skills such as taking a derivative or coding a recursive function. Finally, we designed a pipeline that takes students on one end and produces \"professionals\" on the other end. Those \"smart\" enough to learn to beat the system get the highest grades and are stamped with an abstract generic title of Computer Scientist, Medical Doctor, Lawyer, very much like a certificate of quality in a generic bottle of wine. This system is deeply flawed, and educators all over the world know it and have been discussing it for a long time. It's hard to change for many reasons, the least of which is the lack of teachers willing to dump the generic instruction set and craft custom learning paths for their students. I think this system is based on two basic assumptions, intuitive but flawed. Changing those assumptions could shed light on ways to improve the system. 1\ufe0f\u20e3 The first assumption is that students are a blank slate that when fed through this generic pipeline we call higher education will be magically morphed into this generic professional we designed. This is wrong for so many reasons that is hard to acknowledge it as a basic assumption of our system. \ud83d\udc49 Ask any university professor and they will all tell you the same: All students are different. They all have different skills, interests and biases. They all require a different approach to get the most out of them. And almost all of them, when given the chance and the right environment, will become the best versions of themselves. Yet time and time again we treat them as generic droids on which we can dump a generic course and expect a generic performance in return. 2\ufe0f\u20e3 The second assumption, I think, is harder to spot, because of the way the university is disconnected from real life all around the world. We educators think that society wants this \"model of the professional\" because we think that a hospital needs 100 equally generic doctors, and a software company needs 100 equally generic programmers. However, this is also wrong at many levels. \ud83d\udc49 Everywhere we ask in the industry we keep hearing the same: we need unique people with unique skills that bring something new to the team. It's like trying to build an ensemble out of 100 equal models. You get much better results with a variety of approaches to the same problem, than with an array of 100 exactly equal programs. Yet we keep translating what society asks into skills and competencies. They tell us they need unique people, and we add \"uniqueness\" to the set of generic skills we want to teach with our generic college programs! So let's dump those two assumptions and acknowledge that we have a bunch of different kids with different interests and capabilities, and we need to turn them into a bunch of different professionals with different mindsets and skills. Now the question is how on earth can we do that? As engineers, we need to design a streamlined pipeline and a proper evaluation metric. And we need to do that, unfortunately, because there are so many more students than teachers that we cannot hope to be the Aristotle to each Alexander, and that's not about to change in the near future. I think one possible strategy is to focus on a single evaluation metric, and a single skill: \ud83d\udca1 Strive to transform every student into an effective team-player. Let's take it piece by piece. Every student is different, so everyone will have a different set of potential capabilities that could make them effective team-players. If we encourage those specific capabilities on each student, we are giving each one a different learning path. This one will focus on improving her analytical skills, that one will focus on improving his management skills, the other one her social skills, and so on. Each one is focusing on their own most interesting, most desirable version of themselves. On the other hand, everyone is optimizing the same metric, being a good team-player, whatever the team. Give them back to society and they will fit in the right spot. The one spot that needs that specific mindset. Almost all low-hanging fruits that a single bright person could take are already taken, the problems that are left to solve as a society are the hard problems, and they all require teamwork. The easier problems are being automated away as I type. So, I argue, the most important skill today is being an effective team-player. If we strive to turn our students into exactly that, we are giving them the best education possible, and we are giving society the best possible return on that investment. The final question is how exactly do we do that? How do we discover what makes every student unique and valuable in a team? Isn't that the same Aristotle & Alexander dilemma? I think a possible solution is simply to let each of them discover it by themselves. As educators, instead of trying to tell everyone what to do, let's focus on designing learning environments that are comfortable for every student to explore their own skills and capabilities and decide the best way to serve the team. And let's evaluate them on co-op instead of solo so that when trying to beat the system, they will effectively optimize what we, the rest of the world, need them to be good at. \ud83d\udde8\ufe0f This is a topic of which I'm very passionate about, and I want to hear your feedback. If you want to discuss this topic with me, give me a shout in Twitter . \ud83d\udeab If you find some typo, error or you have any suggestion to help me improve this page, you can suggest and edit or open an issue in Github .","title":"Team-playing"},{"location":"essays/team-playing/#its-all-about-team-playing","text":"Modern higher education is all about competences and skills. In the process, we are losing some very bright people who just don't fit this narrow-minded model of professionalism. Modern education started with the Industrial Revolution and the need to graduate tons of skilled workers to carry on the same tasks over and over. Previously, education was only for the brightest and/or luckiest, and usually consisted of a very custom path through which a tutor would guide you. Nowadays in universities all around the world, we have reduced students to numbers, grades, percentages, as if we were producing computer chips or combustion engines. Efficiency is all that matters. To achieve the highest possible efficiency, all around the world we educators have become engineers of sorts. We designed what we call a \"model of the professional\", which is a set of skills and competencies that an abstract ideal professional should have. Then we designed an evaluation metric he micro-average of a ton of super-narrow scores that measure super-specific skills such as taking a derivative or coding a recursive function. Finally, we designed a pipeline that takes students on one end and produces \"professionals\" on the other end. Those \"smart\" enough to learn to beat the system get the highest grades and are stamped with an abstract generic title of Computer Scientist, Medical Doctor, Lawyer, very much like a certificate of quality in a generic bottle of wine. This system is deeply flawed, and educators all over the world know it and have been discussing it for a long time. It's hard to change for many reasons, the least of which is the lack of teachers willing to dump the generic instruction set and craft custom learning paths for their students. I think this system is based on two basic assumptions, intuitive but flawed. Changing those assumptions could shed light on ways to improve the system. 1\ufe0f\u20e3 The first assumption is that students are a blank slate that when fed through this generic pipeline we call higher education will be magically morphed into this generic professional we designed. This is wrong for so many reasons that is hard to acknowledge it as a basic assumption of our system. \ud83d\udc49 Ask any university professor and they will all tell you the same: All students are different. They all have different skills, interests and biases. They all require a different approach to get the most out of them. And almost all of them, when given the chance and the right environment, will become the best versions of themselves. Yet time and time again we treat them as generic droids on which we can dump a generic course and expect a generic performance in return. 2\ufe0f\u20e3 The second assumption, I think, is harder to spot, because of the way the university is disconnected from real life all around the world. We educators think that society wants this \"model of the professional\" because we think that a hospital needs 100 equally generic doctors, and a software company needs 100 equally generic programmers. However, this is also wrong at many levels. \ud83d\udc49 Everywhere we ask in the industry we keep hearing the same: we need unique people with unique skills that bring something new to the team. It's like trying to build an ensemble out of 100 equal models. You get much better results with a variety of approaches to the same problem, than with an array of 100 exactly equal programs. Yet we keep translating what society asks into skills and competencies. They tell us they need unique people, and we add \"uniqueness\" to the set of generic skills we want to teach with our generic college programs! So let's dump those two assumptions and acknowledge that we have a bunch of different kids with different interests and capabilities, and we need to turn them into a bunch of different professionals with different mindsets and skills. Now the question is how on earth can we do that? As engineers, we need to design a streamlined pipeline and a proper evaluation metric. And we need to do that, unfortunately, because there are so many more students than teachers that we cannot hope to be the Aristotle to each Alexander, and that's not about to change in the near future. I think one possible strategy is to focus on a single evaluation metric, and a single skill: \ud83d\udca1 Strive to transform every student into an effective team-player. Let's take it piece by piece. Every student is different, so everyone will have a different set of potential capabilities that could make them effective team-players. If we encourage those specific capabilities on each student, we are giving each one a different learning path. This one will focus on improving her analytical skills, that one will focus on improving his management skills, the other one her social skills, and so on. Each one is focusing on their own most interesting, most desirable version of themselves. On the other hand, everyone is optimizing the same metric, being a good team-player, whatever the team. Give them back to society and they will fit in the right spot. The one spot that needs that specific mindset. Almost all low-hanging fruits that a single bright person could take are already taken, the problems that are left to solve as a society are the hard problems, and they all require teamwork. The easier problems are being automated away as I type. So, I argue, the most important skill today is being an effective team-player. If we strive to turn our students into exactly that, we are giving them the best education possible, and we are giving society the best possible return on that investment. The final question is how exactly do we do that? How do we discover what makes every student unique and valuable in a team? Isn't that the same Aristotle & Alexander dilemma? I think a possible solution is simply to let each of them discover it by themselves. As educators, instead of trying to tell everyone what to do, let's focus on designing learning environments that are comfortable for every student to explore their own skills and capabilities and decide the best way to serve the team. And let's evaluate them on co-op instead of solo so that when trying to beat the system, they will effectively optimize what we, the rest of the world, need them to be good at. \ud83d\udde8\ufe0f This is a topic of which I'm very passionate about, and I want to hear your feedback. If you want to discuss this topic with me, give me a shout in Twitter . \ud83d\udeab If you find some typo, error or you have any suggestion to help me improve this page, you can suggest and edit or open an issue in Github .","title":"It's all about team-playing"},{"location":"tweetstorms/","text":"I recently discovered that Twitter can be an amazing place to share short, actionable pieces of content that convey one specific message. These are topics that I haven't developed enough to become an essay, and probably never will, but I still find them interesting and worthy of sharing. Not everything I write on Twitter is saved here, only those pieces of content that have enough value I think someone might be interested in bookmarking. But this content is only the tip of the iceberg, the real value is in the conversation they spark on Twitter. So, after reading them, make sure to click on the link at the end which will take you to the thread on Twitter, and there you'll find a lot of opinions, discussion, and insights. If you want to read more thoughtful stuff, I also have some short essays where I take a longer time to explore more complex ideas. These threads are organized into five topics which, for silly reasons, I named after the days of the week. So, every week I try to do two or three of these, and according to the day in which they are published, the topic is more or less consistent. \ud83e\udd2f Mindblowing Mondays are about cool things in Computer Science that are just awesome. \ud83e\udd13 Technical Tuesdays are about practical tools or libraries you can start using right away. \ud83e\udd29 Wisdom Wednesdays are about tips and hints to help you improve and grow as an individual. \ud83e\uddd0 Theory Thursdays are about theoretical aspects of Computer Science that are intriguing to me. \ud83e\udd14 Philosophical Fridays are about philosophical aspects of Computer Science for which there is no right answer, just interesting discussions.","title":"\u2753 About tweetstorms"},{"location":"tweetstorms/mindblowingmonday-gan/","text":"Hey, today is #MindblowingMonday \ud83e\udd2f! A day to share with you amazing things from every corner of Computer Science. Today I want to talk about Generative Adversarial Networks \ud83d\udc47 \ud83c\udf6c But let's begin with some eye candy. Take a look at this mind-blowing 2-minute video and, if you like it, then read on, I'll tell you a couple of things about it... Generative Adversarial Networks (GAN) have taken by surprise the machine learning world with their uncanny ability to generate hyper-realistic examples of human faces, cars, landscapes, and a lot of other stuff, as you just saw. Want to know how they work? \ud83d\udc47 There are many variants, but the core idea is to have 2\ufe0f\u20e3 neural networks: \u2699\ufe0f a generator network \u2696\ufe0f a discriminator network Both networks are connected in a sort of adversarial game, where each is trying to outperform the other. \u2696\ufe0f The discriminator is a regular neural network whose job is to determine if a specific sample (say, an image of a face) is real or generated. This network's architecture depends on the classification task, as usual, e.g., lots of convolutions and pooling for images. \u2699\ufe0f The generator network is a decoder network, whose job is to transform an input of random values to whatever you want to generate. In images, for example, you'll have deconvolution layers and upsampling, i.e., the \"reverse\" of an image classification network. \ud83c\udfa9 All the magic happens in the training. You train the discriminator by alternatively showing it real and generated images, and minimizing some classification loss (e.g., binary cross-entropy). The generator is trained to try and \"fool\" the discriminator. But this is not easy, so the trick involves letting it \"see\" the discriminator loss function. \ud83d\udca1 It's like showing you my brain while you perform a magic trick, so you can understand how I can be fooled best. This is the basic idea, but the devil is in the details. Two common problems with GANs are: 1\ufe0f\u20e3 The discriminator learns much faster, so the generator never gets a chance to catch up. 2\ufe0f\u20e3 The generator gets complacent and just produces the same good examples over and over. \ud83e\udd14 Finally, beyond the technical challenges, the possibility of suddenly creating very realistic content opens a can of worms of ethical issues such as disinformation. But technology itself is neither good nor bad, it is just a tool. It's on ourselves what we do with it. As usual, if you like this topic, have any questions, or just want to discuss, reply in this thread or @ me any time. I'll be listening. This thread is available in plain format here, forever: https://apiad.net/tweetstorms/mindblowingmonday-gan/ Stay curious: \ud83c\udfa5 https://apiad.net/to/#gan-video \ud83c\udfeb https://deepgenerativemodels.github.io/ \ud83d\udcd8 https://www.manning.com/books/gans-in-action \ud83d\udcc3 https://arxiv.org/abs/1710.07035 \ud83d\udcbb https://github.com/nightrome/really-awesome-gan \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Generative Adversarial Networks"},{"location":"tweetstorms/mindblowingmonday-languagemodels/","text":"Hey, today is #MindblowingMonday \ud83e\udd2f! I want to tell you about Language Models, a type of machine learning techniques that are behind most of the recent hype in natural language processing. \u2753 Want to know more about them? \ud83e\uddf5\ud83d\udc47 A language model is a computational representation of human language that captures which sentences are more likely to appear in a given language. \ud83c\udfa9 Formally, a language model is a probability distribution over the sentences in a language. \u2753 What are they used for? \ud83d\udc47 \u2699\ufe0f Language models allow computers to understand and manipulate language at least to some degree. They are used in machine translation, speech to text, optical character recognition, text generation, and many more applications! They come in many flavors \ud83d\udc47 The simplest language model is the unigram model , also called a bag of words (BOW). \ud83d\udc49 In BOW, each word is assigned a probability Pi, and the probability of a sentence is computed assuming all words are independent. But of course, this isn' true. For example, \"water\" is a more commonly used word than \"philosophy\", but the phrase \"philosophy is the mother of science\" is arguably much more likely than the phrase \"water is the mother of science\". \ud83d\udca1 The likelihood of a phrase depends upon all its words. This dependency can be modelled with an n-gram model, in which the likelihood of a word is computed w.r.t. the words before in a given phrase (in a window of size n). \ud83d\udca1 If we start a phrase with \"philosophy\", is more likely to see the word \"science\" than \"shark\". \u261d\ufe0f The problem with n-gram models is that the total number of parameters you need to store grows exponentially with n. If you want to capture phrases of length n=10, you need N^10 numbers, where N is the number of words in the language! \u2b50 Neural language models (aka continuous space language models) are a solution to this exponential explosion. They try to learn jointly a vectorial representation for all words (aka an embedding) and some mathematical operation among them that approximates the likelihood. \u2699\ufe0f Neural language models are built by training a neural network to predict some relationships between words and the phrases in which they appear. The most popular neural language model is possibly word2vec , trained in predicting a word given a small window around it. \ud83d\udc49 Modern neural language models have more complex neural network architectures. Popular examples are BERT and the family of GPT models, of which GPT-3 recently took Twitter by surprise with its ability to speak nonstop about anything, often without much sense. \ud83d\ude07 The nice thing about language models is that they can be trained independently of any NLP problem and then used inside specific applications with a little fine-tunning. \ud83d\ude07 They also improve efficiency. A big company (like OpenAI or Google) can train a big language model and then the rest of us mortals can use them without having to pay millions in GPU training time. \u26a0\ufe0f But they don't come without issues \ud83d\udc47 \ud83e\udd14 Language models encode \"common\" language used, so all human bias is implicitly stored in them. For example, the phrase \"boy is a programmer\" is considered more likely by a model than \"girl is a programmer\", simply because the Internet has more examples of the first phrase. \u261d\ufe0f If used without care, these language models will introduce subtle biases in your application that are very hard to discover and debug. Understanding and fixing these biases is one of the most exciting and important issues in AI safety! As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/mindblowingmonday-languagemodels Stay curious \ud83d\udd96: \ud83d\udcc3 https://en.wikipedia.org/wiki/Language_model \ud83d\uddde\ufe0f https://arxiv.org/abs/2005.14165 \ud83d\udcbb https://github.com/huggingface/transformers \ud83c\udfa5 https://youtu.be/89A4jGvaaKk \ud83c\udfa5 https://youtu.be/_x9AwxfjxvE \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Language Models"},{"location":"tweetstorms/philosophyfriday-aisafety/","text":"Today is #PhilosophyFriday \ud83e\udd14! I want to talk about the ethical implications of using AI, but this is a HUGE topic. So today I'll focus on one specific issue: \u2753 Who do you blame when the AI fails? \ud83e\uddf5\ud83d\udc47 We are surrounded by narrow artificial intelligence systems all over. Our news feeds, video and music recommendations, credit score and many other decisions are being taken by AI-powered computer programs. \ud83d\udca3 Inevitably, they fail, like all software. Some of the most public failures recently have happened with self-driven cars. In a few cases, this has resulted in severe damage to the driver and/or others around it. \u2753 The question is, who do you blame? The easy answer is to blame the programmers, or in general, the company that produced the vehicle. But this answer gets trickier the more advanced the AI becomes. As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/philosophyfriday-aisafety Stay curious \ud83d\udd96: \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Philosophyfriday aisafety"},{"location":"tweetstorms/philosophyfriday-computability/","text":"Today is #PhilosophyFriday \ud83e\udd14! Today we'll be talking about the philosophical problem that kick-started all of Computer Science! \u2753 Can we answer all mathematical questions? \ud83e\uddf5\ud83d\udc47 \ud83d\udcc6 At the turn of the 20th century, the success of geometry, algebra, analysis and logic was hinting that it should be possible to unify all mathematics under a single theory. Each of these fields had proven extremely useful, and there were seemingly not many problems left. So they got together in 1900 to discuss the future of mathematics, and decide which were the most important problems left. \ud83c\udfa9 David Hilbert proposed 23 problems that he said should be solved by the end of the century. Today, all but 6 are either resolved or proven unsolvable. But there is one that had far-reaching implications beyond mathematics. The question is this: \ud83d\udc49 Prove that the axioms of arithmetic are consistent. Stated like this, it seems mostly harmless. But what does it mean? Intuitively, an axiomatic system is consistent if there is no way you can prove a contradictory fact using logic. This is super important, because if a theory allows internal contradictions to exist, then you could prove whatever crazy thing you want! (\ud83e\udd14 Politics, anyone?) Hilbert was convinced that, of course, arithmetic has to be consistent! \u261d\ufe0f Otherwise, math itself, the purest intellectual invention of humanity, would be nothing different from the daily rambling of crazy people. The answer, it turns, is absolutely mind-blowing. In 1931, Kurt G\u00f6del proved something incredible: \ud83e\udd2f In any sufficiently strong mathematical theory, there are always some true theorems that nevertheless cannot be proven within that theory. Moreover, the question \"is this theory consistent?\" is one of them. This was the first nail in the coffin of mathematical self-righteousness. \ud83d\udc49 If arithmetic, analysis, or algebra is consistent (which we hope they are), then that cannot be proven by mathematical means using arithmetic, analysis, or algebra. The second nail came a couple of years later. \ud83e\udd2f In 1933 Alfred Tarski proved that, in any sufficiently strong mathematical theory, the concept of \"truth\" cannot be formally defined inside that theory. The final nail was put simultaneously by Alan Turing and Alonso Church in 1936. \ud83e\udd2f They both showed, by different means, that it is impossible to write an algorithm to determine if any given theorem can be proved from a set of axioms. These results collectively showed that there are very important questions in mathematics that we cannot answer within mathematics. \ud83d\udca1 We cannot objectively define what truth is. \ud83d\udca1 We cannot prove all truths. \ud83d\udca1 We cannot be sure we don't have internal contradictions. Up to 1930, most mathematics believed there was no such thing as an \"unsolvable\" problem. Now we know there are plenty. Many are esoteric problems, but some are very concrete. One of the most relevant ones is this: \ud83d\udc49 There is no way to be 100% sure a program is correct. What does this mean, philosophically speaking? \u2b50 It shows that there is an inherent gap between what is true, and what can be known. Mathematics, and by extension, Computer Science, cannot give us all the answers. Is up to you to choose what this means for you. As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/philosophyfriday-computability Stay curious \ud83d\udd96: \ud83c\udfa5 https://youtu.be/O4ndIDcDSGc \ud83c\udfa5 https://youtu.be/macM_MtS_w4 \ud83d\udcc4 https://en.wikipedia.org/wiki/Hilbert%27s_problems \ud83d\udcc4 https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Computability"},{"location":"tweetstorms/philosophyfriday-intelligence/","text":"Hey, today is #PhilosophyFriday \ud83e\udd14! How about discussing some philosophical aspects of Computer Science? Today's question is: \u2753 How do you know someone (or something) else is intelligent? \ud83e\uddf5\ud83d\udc47 Before even asking the question of whether machines can or not ever become \"intelligent\", we need to ask ourselves: if they do, how would we know? The underlying question is, of course, what is intelligence? \ud83d\udc47 There are many ways to answer this question, and not a single one will be complete, of course. You have to consider psychology, neurobiology, even philosophy and ethics... From the computational point of the view, the most famous one is the Turing Test \ud83d\udc47 It goes like this: A \ud83d\udc69human and a \ud83d\udcbbcomputer take turns to chat with a \ud83d\udc69\u200d\u2696\ufe0fjudge. \ud83d\udc69\u200d\u2696\ufe0f is free to ask anything to anyone, even \u00bfare you a computer? Both \ud83d\udc69 and \ud83d\udcbb are trying to convince the judge they are human. \ud83d\udc49 If \ud83d\udc69\u200d\u2696\ufe0f fails to identify \ud83d\udc69 as the human, we are forced to recognize \ud83d\udcbb exhibits intelligence. \ud83d\udca1 The intuition behind this test is that, even if we cannot precisely define what intelligence is, we can all recognize it in others. \u26a0\ufe0f There has been a lot of criticism to Turing's Test, invoking among other issues: 1\ufe0f\u20e3 The judge may be easily fooled with cheap tricks, unless well trained. There are plenty of examples of simple chatbots that appear human because we tend to anthropomorphise things. 2\ufe0f\u20e3 Human intelligence might not be equivalent to general intelligence, so an intelligent computer (or an alien individual) might not be recognized as such, simply because it doesn't fit our narrow conception of intelligence. 3\ufe0f\u20e3 And there is the issue of whether \"simulating intelligence\" is the same as \"being intelligent\". This is John Searle's argument, commonly known as the \"Chinese Room\", which takes a philosophical stance against the computational nature of intelligence. \ud83e\udd14 The philosophical question we have to ask ourselves here is about the nature of intelligence. \u2753 Is intelligence a purely computational process, independent of the underlying hardware? Or does it depend on something inherent to biological brains? \ud83e\udde0 If you believe intelligence requires biological brains, then you are \"biological naturalist\", as John Searle. You don't think is possible for our computers to become truly intelligent irrespective of how powerful they become. At most they could simulate intelligence. \ud83e\udd16 Otherwise, you are a \"computationalist\", or \"functionalist\", as Alan Turing. You believe that minds are \"just\" sufficiently powerful computers, so nothing in principle stops our computers from becoming truly intelligent. It's just a matter of time. \ud83d\udc49 Whatever you chose to believe, some very smart people will agree with you. Either way, even if there are some examples of \"winning the Turing Test\", if all serious computer scientists agree on something, that is we are still far away from Strong AI. As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/philosophyfriday-intelligence Stay curious \ud83d\udd96: \ud83d\udcda https://www.csee.umbc.edu/courses/471/papers/turing.pdf \ud83d\udcc3 https://en.wikipedia.org/wiki/Turing_test \ud83d\udcc3 https://iep.utm.edu/chineser/ \ud83c\udfa5 https://www.youtube.com/watch?v=Qbp3LJvcX38 \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"The Turing Test"},{"location":"tweetstorms/philosophyfriday-mary-room/","text":"Hey, today is #PhilosophyFriday \ud83e\udd14! How about discussing some philosophical aspects of Computer Science? Today I want to talk about Mary's Room \ud83d\udc47 This is a very interesting thought experiment that is related to the nature of knowledge and the difference between knowing something and knowing about something. There are many variants of the experiment, but my favorite one goes like this \ud83e\uddf5: Mary is a renowned neuroscientist who has studied everything there is to study about human vision. She understands every little bit of science regarding how light enters the eye, how it is received, and how it is processed in the brain... \ud83d\udc47 Furthermore, Mary understands perfectly all the physics of color, she can say exactly which portion of the spectrum is called \"red\", \"green\", \"blue\", or any other color you can mention... \ud83d\udc47 Even more, Mary has interviewed thousands of people, scanned their brains, measured their retinas. She understands all the physical phenomena that happen when everyone else sees a color... \ud83d\udc47 But... Mary is absolutely color blinded. She has a rare genetic disease that makes her see everything in monochrome. So, being the top researcher in the whole world regarding the human experience of color, she has never \"experienced\" color herself... \ud83d\udc47 One day, a miracle of science allows Mary to regain the ability to see color, in all its glory. And for the first time in her life, Mary looks up, and she experiences the blue sky \u2601\ufe0f! \u2753 At this point, does Mary gain any new knowledge that she didn't previously have? Think carefully. There is no right or wrong answer, just let me know at this point what do believe and, more importantly, why. Before you leave, I have a few more comments to make \ud83d\udc47 \ud83c\udd70\ufe0f If you think Mary doesn't learn anything new, then you believe in \"physicalism\": the notion that the physical world is everything there is. In particular, all human experience is ultimately caused by physics and there is nothing above it. \ud83c\udd71\ufe0f If you think there is something new she attained after experiencing color, that she couldn't possibly have known before, then you believe in the existence of \"qualia\": subjective experiences that cannot be explained or understood without experiencing them. \ud83e\udd14 Most philosophers and scientists (including computer scientists) describe themselves as physicalists or at least materialists. However, it is very hard to explain what I experience as \"being red\" or \"being cold\" or \"being painful\", without having you experience it. \"But what does this have to do with computers\", you ask? Well, if qualia exist, then it is very hard to believe in strong artificial intelligence. Since computers will not experience the world the way we do, how will you know that they know what \"pain\" or \"love\" is? And that's it. Now I just want to leave the discussion open. There is no right or wrong answer here since philosophers themselves don't even agree (this is hardly surprising, though, put N philosophers in a room and you will have N+1 opinions \ud83d\ude06). If you want to read this in a more \"classic\" format or bookmark it for later, check it out here: https://apiad.net/tweetstorms/philosophyfriday-mary-room/ \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Mary's Room"},{"location":"tweetstorms/philosophyfriday-orth/","text":"Today is #PhilosophyFriday \ud83e\udd14! I want to talk about the ethical implications of using AI, but this is a HUGE topic. So today I'll focus on one specific issue: \u2753 Will super-intelligent beings be nice to us? \ud83e\uddf5\ud83d\udc47 \ud83d\udc7d One of the great fears of humanity, and science fiction authors, in particular, is what would happen if we encounter super-intelligent alien species in the near future. Would they destroy us, adopt us, teach us, or ignore us? \ud83d\ude07 Some pretty clever people think that sufficiently advanced civilizations have to be \"good\", otherwise, they would have probably destroyed themselves. Being a dick would be kind of a Great Filter. Violent civilizations would not survive long enough to conquer the Galaxy. \ud83d\ude08 Others have the opposite view. Super-intelligent civilizations would have to be \"nasty\". Otherwise, they would have been destroyed by their enemies. In this view, being a dick would be evolutionarily inevitable. \ud83d\ude11 Others have the view that intelligence and moral are two orthogonal dimensions. You could have super-intelligent beings which are super good, super bad or anything in-between. Or they could have moral values completely incomparable to ours, unclassifiable as good or bad. \ud83d\uddfa\ufe0f If history tells us anything, there is no evidence that technologically advanced civilizations are any nicer than their less advanced neighbours. Such an encounter has never ended well for the least advanced civilization. But who's to say there isn't a technological level after which being good is a condition for further progress? We may very well be at the brinks of this transition right now. \u2753 What do you think? Why is this relevant? If we invent super-intelligent AI someday, they could be like aliens to us. \ud83d\udc4d If goodness is a necessary condition of super-intelligence, we have nothing to worry about. \u26a0\ufe0f Otherwise, we may already have little time left to solve this problem. And if there is even a small chance that we end up being destroyed by our god-children, shouldn't we be paying more attention to this problem? \u261d\ufe0f There are lots of pressing issues with AI today, though. Deciding what to prioritize is also important. As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/philosophyfriday-orth Stay curious \ud83d\udd96: \ud83d\udcc4 https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence \ud83d\udcda https://www.goodreads.com/book/show/44767248-human-compatible \ud83d\udcda https://www.goodreads.com/book/show/20527133-superintelligence \ud83c\udfa5 https://youtu.be/hEUO6pjwFOo \ud83c\udfa5 https://youtu.be/8nt3edWLgIg \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Orthogonality Thesis"},{"location":"tweetstorms/philosophyfriday-simulation/","text":"Hey, today is #PhilosophyFriday \ud83e\udd14! How about discussing some philosophical aspects of Computer Science? Today's question is: \u2753 How do you know you're not living in a simulation? \ud83e\uddf5\ud83d\udc47 This idea is called the simulation hypothesis and it exists, in some form, way back in ancient Greek, Mayan, and Indian philosophy, passing through Descartes and Berkeley, and more recently popularized by Nick Bostrom. The modern (and simplified) version goes like this \ud83d\udc47 Either: 1\ufe0f\u20e3 it is impossible to simulate a high-fidelity universe; or 2\ufe0f\u20e3 any civilization capable of doing so has no interest in doing it; or 3\ufe0f\u20e3 we are living in a simulated universe. \u2753 Stop now and tell me what do you think? Let's analyze each alternative. 1\ufe0f\u20e3 It may well be that simulating a universe is impossible because of quantum mechanics or other unknown physical restrictions that we today don't understand. That is, high-fidelity physics might be uncomputable. \u261d\ufe0f But, there is little evidence for this, since we are already capable of simulating a nice chunk of physics, and it seems all we need is more computing power. The advent of quantum computers might make this possible, even if very costly. 2\ufe0f\u20e3 If it's possible to simulate a high-fidelity universe, then any civilization that can do it in principle will do it, unless: \ud83c\udd70\ufe0f it is way too costly to be of any value; or \ud83c\udd71\ufe0f it is morally forbidden, out of a sense of respect for the simulated individuals' lives. \u261d\ufe0f Sadly we have little evidence that morals would stop the human civilization from simulating other individuals, giving our history. Maybe \"mature\" civilizations are different. 3\ufe0f\u20e3 If it's technically feasible and interesting for any civilization advanced enough to simulate a high-fidelity universe, then we are almost certainly living in one. \u2753 Why? Either we are simulated or we are not. In either case, with enough computing power, we will be able to simulate a universe ourselves, since this universe is either real or a high-fidelity simulation. \ud83d\udca1 So there should be arbitrarily deep hierarchies of simulated universes. Hence, what is more likely? That we just happen to be the one civilization at the top of the hierarchy, or that we are somewhere inside the hierarchy? Without further prior evidence we must believe that all steps in the hierarchy are equally likely. \u261d\ufe0f So, we are simulated. \ud83e\udd2f Think about the implications! Either you believe simulating a universe is physically impossible or universally tabu, or you have to believe you are living inside a simulation! \u2753 Tell me again, what do you think now? There are plenty of objections to this thought experiment but, in principle, if we were living inside a simulation, we could be unable to prove it, since any evidence we gather could be part of the simulation. \ud83d\ude2c So, science appears to have no way to attack this problem. Recently, a compelling argument from @neiltyson has brought peace to my mind again, turning the hierarchy logic on its head. \u261d\ufe0f Given that almost all movies are based on the modern era, if we are simulated, why would we exist in the pre-simulation era? \ud83d\ude01 In any case, if we are living inside a simulation, maybe it's better if we don't find out. That could be the \"game over\" after which the simulation is restarted. As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/philosophyfriday-simulation Stay curious \ud83d\udd96: \ud83d\udcda https://www.simulation-argument.com/simulation.pdf \ud83d\udcc3 https://en.wikipedia.org/wiki/Simulation_hypothesis \ud83d\udcc3 https://en.wikipedia.org/wiki/Simulated_reality \ud83c\udfa5 https://youtu.be/nnl6nY8YKHs \ud83c\udfa5 https://youtu.be/pmcrG7ZZKUc \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"The Simulation Hypothesis"},{"location":"tweetstorms/technicaltuesday-automl/","text":"Today is #TechnicalTuesday \ud83e\udd13! Let's talk about practical technologies that you can use today. In this thread I will tell you about AutoML \ud83e\uddf5\ud83d\udc47 AutoML stands for Automated Machine Learning . It encompasses a bunch of technologies and paradigms to gradually automate the process of creating machine learning solutions. \ud83d\udca1 AutoML is about raising the abstraction level in ML and reducing the grunt work. \u2753 What can AutoML do today? Getting a machine learning solution to work takes a few steps: 1\ufe0f\u20e3 collecting data 2\ufe0f\u20e3 sanitizing that data 3\ufe0f\u20e3 finding the best model 4\ufe0f\u20e3 training that model 5\ufe0f\u20e3 and beyond, actually build the product\u2757 Most current AutoML frameworks today focus on 3\ufe0f\u20e3, i.e., helping you select among the plethora of machine learning models which is the best for your problem. This problem is often framed in terms of: \ud83c\udd70\ufe0f model selection \ud83c\udd71\ufe0f hyperparameter optimization \ud83c\udd70\ufe0f Model selection is about deciding, e.g., if logistic regression, decision trees or SVM is better, or whether to encode with word2vec or TF-IDF. The \"manual\" way of doing this is to actually try each algorithm a bunch of times in your data and collect some statistics. \ud83c\udd71\ufe0f Hyperparameter optimization is about selecting the exact value for each tunable thing in your algorithm. How many neurons? How much dropout? Which activation function? Which regularization factor? ... If you combine both problems, then you realize there are literally thousands (and potentially infinite) different algorithms you can try on your data. If you were to do this yourself, the simplest solution is something like this: \u2b50 Actually, AutoML algorithms are way smarter and faster than random search. \ud83d\udca1 AutoML frames this problem as an optimization loop on top of the training loop and applies a lot of clever optimization tricks. \ud83d\udc49 AutoML frameworks hide away all that complexity behind an interface that looks as if you are training a single model, but it is ultimately doing the search and optimization loop under the hood. Let's see a couple of examples \ud83d\udc47: \u2764\ufe0f Auto-Sklearn is an AutoML framework compatible with scikit-learn. \ud83d\udd17 https://automl.github.io/auto-sklearn/master/ You can basically replace standard scikit-learn code with a generic Auto-Sklearn classifier and suddenly you are evaluating thousands of models: \u2764\ufe0f Auto-Keras is an AutoML framework specifically designed for deep learning with Keras. \ud83d\udd17 https://autokeras.com/ Instead of manually designing a neural network, you can use Auto-Keras predefined \"meta-models\" and it will take care of finding the best architecture: Yeah, I know \ud83e\udd2f! And AutoML is much more than model selection and hyperparameter search. It can also include automating: data preprocessing feature engineering feature selection dataset augmentation model distillation and more... \ud83d\udd11 If you are working on a practical problem today there is no reason not to use AutoML. \ud83d\udd11 Even if you are working on research, AutoML will make you more productive by taking care of the dumb tasks and letting you focus on the important parts. \u2757However, this is no silver bullet. There are a lot of challenges to make AutoML production-ready. Data cleaning is a major bottleneck still, far from automated. And we need to understand how these methods exacerbate data bias. Finally, if you are feeling adventurous, you can try @auto_goal , an experimental AutoML framework that goes beyond \"standard\" AutoML. \u2b50 Check it out in https://autogoal.github.io ! As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/technicaltuesday-automl Stay curious \ud83d\udd96 \ud83d\udd17 https://www.automl.org/automl/ \ud83d\udcda https://www.automl.org/book/ \ud83c\udfa5 https://youtu.be/3c0FoQrsJxo \ud83c\udf81 https://github.com/windmaple/awesome-AutoML \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"AutoML"},{"location":"tweetstorms/technicaltuesday-streamlit/","text":"Today is #TechnicalTuesday \ud83e\udd13! Let's talk about practical technologies that you can use today. In this thread, I will tell you about @streamlit \ud83e\uddf5\ud83d\udc47 \ud83d\udca1 Streamlit is a Python framework to make data science apps blazingly fast. The core value proposition is that you don't need any HTML, CSS or JavaScript, just pure Python. Take a look: \u2753 Why do you want this? As a data scientist, you spend most of your time designing, experimenting and testing models. You probably use Jupyter Notebooks a lot, right? What happens when you have to show those models working? If you're working for another data scientist, you can probably just share your Python scripts or Notebooks, but at some point in the chain, someone who doesn't ready code will need to see your model in action. At this point, you (or someone) has to build a minimal application, an MVP, that at least shows some input controls, allows you to play with some model parameters, and lets you render some graphs. This often takes the form of a Flask application with a minimal HTML frontend, possibly with a minimum JavaScript. And don't forget CSS. \u2753 The question is, who builds this MVP? \ud83d\udc49 We the data scientists either don't have the skills or we have to spend a ridiculous amount of time dealing with frontend details we couldn't care less (since this is not a product, it's just a demo). \ud83d\udc49 The frontend team is usually busy with, you know, building the real product, and it's ineficient to use their time for building this app which, again, is not the final product. \ud83e\udd37 But someone has to do it. Enter @streamlit . The frontend framework for pragmatic data scientists. \ud83d\udc4d Forget about writing any HTML, CSS or JavaScript. Everything is pure Python code, and you get a nice reactive for free. \ud83d\udc4d Forget about routes, templates, sessions and global state. Your code looks exactly like a Python script because it is a Python script. Everything is executed top-to-bottom every time the user changes something. \ud83d\udc4d And you get a super powerful caching mechanism as a simple Python decorator that you can use in any heavy method (e.g., downloading data, training a model). So forget about having to manually store all that data. There is one main caveat: \u26a0\ufe0f You have very little customization for layouts or styling. But you don't care about that, remember, this is not the final product, is just a demo to showcase some prototype model. If you're like me, you just want to have a frontend to show today with the least possible throw-away effort. \u2b50 Take @streamlit for a spin today. I promise it'll be worth it. As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/technicaltuesday-streamlit Stay curious \ud83d\udd96 \ud83d\udd17 https://streamlit.io/ \ud83d\udcda https://github.com/streamlit/streamlit \ud83c\udfa5 https://www.youtube.com/channel/UC3LD42rjj-Owtxsa6PwGU5Q \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Streamlit"},{"location":"tweetstorms/theorythursday-algorithm-complexity/","text":"Hey, guess what, today is #TheoryThursday \ud83e\uddd0! A silly excuse I just invented to share with you random bits of theory from some dark corner of Computer Science and make it as beginner-friendly as possible \ud83d\udc47 Today I want to talk about Algorithmic Complexity . To get started, take a look at the following code. How long do you think it will take to run it? Let's make that question more precise. How long do you think it will take to run it in the worst-case scenario? We can see that the code will run slower if: \ud83d\udc49 your computer is older; \ud83d\udc49 the array is longer; or \ud83d\udc49 x happens to be further to back, or not present at all. Can we turn these insights into an actual formula? We will have to get rid of ambiguous stuff like \"old computers\". 1\ufe0f\u20e3 First, let's consider an abstract computer in which all \"atomic\" operations take exactly 1 unit of time. \ud83e\udd14 Defining exactly what is an \"atomic\" operation is far from trivial. For now, assume it's things like arithmetic operations, indexing, invocation. 2\ufe0f\u20e3 Second, we'll count the number of operations with respect to the size of an arbitrary array. We will say something like \"this will cost 2 units of time for each element of the array\". 3\ufe0f\u20e3 Finally, we will consider the worst-case scenario. So we assume, in this example, that the element x is not in the array. More generally, we will always think about the maximum number of operations that could potentially happen. With these ideas in mind, we are ready to define the Algorithm Complexity of this algorithm. Let's count how many operations are performed in each step, assuming our array has length N: Depending on how detailed you want to be counting, you could say we have something like \ud83d\udd253*N+1\ud83d\udd25 operations in the ultimate worst-case scenario. \u2753 Now, why do we care about this? The reason is that we can now compare different algorithms. For example, if your implementation takes \ud83d\udd255*N+3\ud83d\udd25, then it is worse, right? Well, it's not \ud83d\ude1d Here's the deal: we have been assuming that all \"atomic\" operations are equally costly, but this is not true... Hence, it makes no sense to compare my implementation with your implementation by looking at those tiny differences. My 5 * N could be faster than your 3 * N if my \"atomic\" operations are simpler. \ud83d\udca1 We want a complexity measure that smooths away all implementation details. To achieve this, we will take away everything unimportant when N becomes very large. We will consider that: \ud83d\udc49 N+a and N+b are the same; \ud83d\udc49 a N and b N are the same; ... for any finite values a and b. \ud83d\udd11 And instead of saying 3*N+4, we will say the asymptotic algorithmic complexity is O(N). This is called big-O notation. \ud83d\udca1 We call this linear complexity because the number of operations grows linearly with respect to the size of the array. \ud83e\uddd0 Formally, it means that your function's cost is something that is bounded by a linear function. \ud83d\udca1 Intuitively, what this means is that in the long run, small differences like specific operations matter less than the capacity your algorithm has to scale with more data. The reason is simple, an algorithm with a lower asymptotic complexity will eventually win. Take for example binary search. https://en.wikipedia.org/wiki/Binary_search_algorithm It takes a bit of thinking, but we can prove the asymptotic notation to be O(log N). Binary search is doing much more work in each iteration than linear search. It could be 20 * log N vs 3 * N. Hence, with very small arrays, linear search could be better. \ud83d\udd11 But there is always a value of N after which binary search will win, and in any hardware. \u2764\ufe0f And that's it. We have just arrived at the intuitive notion of asymptotic complexity! Calculating it can be daunting for some non-trivial algorithms, but here are some tips for estimating it: 1\ufe0f\u20e3 Every nested for loop from beginning to end usually means another exponent. For example, two nested loops usually mean O(N^2), three nested loops, O(N^3), and four nested loops means you really need to take a break and, afterward, please refactor that code. 2\ufe0f\u20e3 An invocation to function F inside a loop means you have to multiply N times the complexity of F. For example, if we call binary search for each element of the array, the resulting algorithm is O(N log N) 3\ufe0f\u20e3 In recursive methods, if you split at the middle and recurse down only one branch, that's O(log N). If you recurse down both branches, you usually have O(N log N). These are special cases of a more general rule for recursive methods: https://en.wikipedia.org/wiki/Master_theorem_(analysis_of_algorithms) Finally, we have just scratched the surface in this thread. Algorithmic complexity is a fascinating topic that touches all fields in Computer Science. The most important problem in all of CS comes from here, the infamous \ud83d\udd25P vs NP\ud83d\udd25. But that's a story for another Thursday \ud83d\ude09. \ud83d\udde8\ufe0f If you like this idea, then get into the conversation! Steal this #TheoryThursday hashtag an tell me about your favourite piece of dark magic. \ud83d\udd14 Just @ me and I'll make sure to weigh in. \ud83d\uddd2\ufe0f Here is the full thread source: https://apiad.net/tweetstorms/theorythursday-algorithm-complexity/ \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Algorithm Complexity"},{"location":"tweetstorms/theorythursday-cfg/","text":"Today is #TheoryThursday \ud83e\uddd0! I want to talk about a tiny part of a topic that is one of my passions: Formal Language Theory. \u2753 Why can't you use regular expressions to process HTML? \ud83e\uddf5\ud83d\udc47 You probably know a bunch of different \"programming\" languages, right? Python, Java, C++, JavaScript, HTML... There have different keywords, expressions, punctuation rules, braces, ... \u2753 What is the one thing they all have in common? \ud83d\udc49 They can be infinitely nested. In all these languages you have some constructions (e.g., expressions) which can be as complex as you desire. These constructions are defined recursively. For example: \u270f\ufe0f An expression is either a number, or a sum, subtraction, multiplication, or division of two expressions. \u2753 But is HTML a programming language or not? Who cares? HTML has recursive constructions as well. From the syntax perspective, which is what we are discussing here, it is of the same nature as all the other. (\u261d\ufe0f We are talking about syntax, not semantics here) \u2b50 These are all called Context-Free languages. Their fundamental characteristic is that they can be defined with a formalism called Context-Free Grammars (CFG). (\u261d\ufe0f There are types of languages which are not context-free) Informally, a CFG is a set of transformation rules that define which sequences of symbols are valid in a given language. For example, take arithmetic expressions: \ud83d\udc4d ( 31 + ( 245 * 15 ) ) -- is a valid sequence \ud83d\udc4e 63 + ) 23 * ( -- is an invalid sequence Here is one possible grammar for expressions. Starting with the symbol <Expression> and applying randomly any rule (called a production ), you will always reach some combination of NUMBER and the symbols + , - , * , / , ( , ) that is valid. This is called a derivation . \ud83d\udc49 What's more, any possible arithmetic expression can be formed by some sequence of applications of that grammar rules. Even better, in this particular example, there is exactly one such sequence for any valid expression. \u2753 Why is this relevant? Because we can analyze the syntactic complexity of all programming languages just by analyzing the language for expressions. They are all equally complex. The fundamental question we want to answer is this \ud83d\udc47 \u2753 What is the simplest program than can recognize all (and only) valid expression? This is called \"parsing\" an expression. I'm sure you've heard the term. \ud83d\udc49 Parsing is finding the sequence of transformations that goes from <Expression> to whatever you want to parse. If that sequence exists, then we know that it is a valid expression, and even more, we know everything we need to evaluate it. \ud83d\udca1 Parsing is the first step that all compilers and interpreters do, from Python to C++, to yes, the HTML parser in Chrome. Now we come round back to regular expressions. \ud83d\udc49 It turns out that standard regular expressions are computationally insufficient to parse any language that requires a context-free grammar. (\ud83d\ude22 While proving this is not hard, sadly it is too long for this thread) You can say, intuitively, that regular expressions cannot \"count\" the matching opening and closing parenthesis. This is because regexes, deep down, are just overpriced finite automata. (\ud83d\ude44 Yes, I know this is more nuanced, I'm talking about standard regexes only) So, next time someone suggests you to \"just use a regex to parse that HTML\", you can \ud83e\udd26 and answer, in formal language lingo: \"no, regexes cannot parse context-free languages\". You won't make any new friends, but at least you'll be right \ud83d\ude1d As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/theorythursday-cfg Stay curious \ud83d\udd96: \ud83d\udcc4 https://en.wikipedia.org/wiki/Context-free_grammar \ud83d\udcda https://suif.stanford.edu/dragonbook/ \ud83c\udfeb https://www.edx.org/course/compilers \ud83d\ude06 https://stackoverflow.com/questions/1732348/ \ud83d\uddbc\ufe0f https://xkcd.com/208/ \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Context-Free Grammars"},{"location":"tweetstorms/theorythursday-pnp/","text":"Today is #TheoryThursday \ud83e\uddd0! I want to talk about what is, possibly, the most important question in all of Computer Science: Does P equal NP? If you have heard of this and want to learn a bit more, read on... \ud83e\uddf5\ud83d\udc47 Computer Science is all about finding clever ways to solve difficult problems. We have found clever algorithms for a bunch of them: sorting stuff, finding shortest paths, solving equations, simulating physics... But some problems seem to be way too hard \ud83d\udc47 One example is the Travelling Salesman problem. \u2753 Find a cycle starting in your home city to visit all major cities in your country and return home with the least fuel cost. This is the kind of problem we expect computers to solve easily, right? That's what computers are for! \ud83d\ude48 Well, very smart people have tried, and no one has come up with an algorithm that is always better than simply trying all possible cycles. The problem is that the number of cycles grows exponentially faster than the number of cities! Let's make it even easier, what about if I simply ask: \u2753 Is it possible to visit all cities spending less than X dollars in fuel? \ud83d\ude48 No one still knows an algorithm to answer that question precisely for any value of X without trying all cycles, which again is exponential. \ud83d\ude2c So, are we simply dumb, or is this problem so complex that it is impossible to find a clever algorithm to solve it, in the general case ? This is the root of possibly the most important question in all of Computer Science: P vs NP. Answering this question is way harder than it seems. You see, most questions in CS are about objects: how to sort, how to compare, how to process... But this is a meta-question: \u2753 Are there questions about objects that are intrinsically very hard to solve? Stephen Cook tried to answer this question in the early days of Computer Science. He came up with the following definitions: Suppose we have a question of the form: \u2753 Is there an object X with a given property Q? \ud83d\udc49 We want to define how hard is this question to answer. An example of an easy question of this type is the following: \u2753 Given an array of N elements, is there an element smaller than X? Answering this question is easy. Look at each element, one by one, and compare it with X. It takes at most N steps, for any possible array. This is an example of a problem in P. \ud83d\udd11 P here means \"Polynomial-Time Complexity\". Intuitively, a problem is in P if there is an algorithm to compute a correct answer in polynomial time. Now back to the Travelling Salesman, suppose I give you an answer: \ud83d\udc49 Yes, here, this is a cycle with cost less than X. How can you verify that answer is correct? You just add the costs of all edges in the cycle. It takes again N steps. This is an example of a problem in NP. \ud83d\udd11 NP here means \"Non-deterministic Polynomial-Time Complexity\". Intuitively, a problem is in NP if there is an algorithm to verify a correct answer in polynomial time. P problems are easy to solve. NP problems, we don't know yet, but at least they are easy to verify. That's the key idea. \u26a0\ufe0f Note that P problems are also NP. Now, the P vs NP question, formally, is this: \u2753 Are there problems in NP that are not in P? P vs NP is basically asking if there are problems that are inherently harder to answer than to verify, independently of how smart we become in the future. \ud83e\udd14 Think about what this means for a second, and ask yourself what's your intuition about it. What's the right answer? We still don't know, but most computer scientists believe that P is not equal to NP. The reasons are mostly philosophical but there is also evidence that, if P were equal to NP, a lot of weird things would happen. This question is at the core of Computer Science because it talks about the nature of computation and its inherent limits, regardless of technological improvements. We'll end here for now, but there is so much left to talk about (like NP-completeness). So stick around \ud83d\udc4b... As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/theorythursday-pnp Stay curious \ud83d\udd96: \ud83d\udcda https://dl.acm.org/doi/10.1145/800157.805047 \ud83d\udcda https://dl.acm.org/doi/10.1145/1562164.1562186 \ud83d\udcc4 https://en.wikipedia.org/wiki/P_versus_NP_problem \ud83c\udfa5 https://youtu.be/dJUEkjxylBw \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"P vs NP"},{"location":"tweetstorms/wisdomwednesday-designthinking/","text":"Today is #WisdomWednesday \ud83e\udd29! Have you ever had an amazing idea, built a product around it, and found out no one wanted it? I have, plenty of times. Part of the issue is we started from the solution, but there is a better way. \u2b50 This is a thread on Design Thinking \ud83e\uddf5\ud83d\udc47 Creating a product, whether a software, a physical thing, or a service, is all about solving a problem. \ud83d\udc49 Someone has a problem, and you offer a solution. But we often start with a solution, in the hope that someone wants it, and we end up solving an inexisting problem. This happens because, in real life, problems are not cleanly written in some kanban board. \u26a0\ufe0f We often know that something is not right, and we think we know how to solve it but, actually, we don't even have a clear idea of what's wrong. Enter Design Thinking \ud83d\udc47 Everything stems from these principles: 1\ufe0f\u20e3 The problem is never well defined. 2\ufe0f\u20e3 The problem and the solution must co-evolve together. 3\ufe0f\u20e3 The solution is never completed. And one key idea: \u2b50 The human being is the most important element of the solution. Based on these principles, the process itself is a continuous cycle of five steps: \ud83d\udd2d Understand \ud83d\udcdd Define \ud83d\udca1 Ideate \ud83d\udee0\ufe0f Prototype \u2697\ufe0f Test \ud83d\udd2d You start by observing people, your potential users or clients. Ask yourself: \u2753 How are they solving the problem now? \u2753 What is their critical pain in doing so? \u2753 Why is that happening? \ud83e\udd14 These questions sound familiar to you? Useful tools and practices: \ud83d\udc49 Observation. Just watch people in their routine and take notes. \ud83d\udc49 Interviews, but not with standardized questionnaires; instead, talk openly with people, and listen. \ud83d\udc49 Ask \"why\" at least 5 times to get to the core of the problems. \ud83d\udcdd Then you have to clearly define one problem to solve. Focus is key here. A good definition is actionable. It describes a situation that is easy to validate when it has been solved. \ud83d\udd2c Go deep, you don't want to solve the superficial problem but the underlying cause. Here are some techniques: \ud83d\udc49 Use a board (physical or virtual) and put a note for every potential insight or problem. \ud83d\udc49 Make clusters, group similar problems and insights together. \ud83d\udc49 Select (or vote on) one cluster and write a clear definition of the problem it represents. \ud83d\udca1 Now it's the fun part, it's time to come up with ideas! This is the creative part of the process, so don't be afraid to have too many ideas. This is a rare case of quantity before quality. \ud83c\udf29\ufe0f The best tool is a brainstorming session. A good brainstorm has these qualities: \ud83d\udc49 Only one person talks at a time, no interruption allowed. \ud83d\udc49 Set a maximum time for each intervention, around 1 minute. \ud83d\udc49 No idea is too crazy or impossible. \ud83d\udc49 Build on top of others: instead of \"no, because\", just say \"yes, and\". \ud83d\udee0\ufe0f Next, it's time to finally build something! Select one, or a few related ideas, and turn it into a prototype. You want to build a Minimum Viable Product (MVP), the smallest piece of functionality that lets you learn something new. \ud83d\udd25 Don't overengineer. You know you are overengineering when: \ud83d\udc49 You care about how it looks (unless that's the problem). \ud83d\udc49 You care about how fast it is (unless that's the problem). \ud83d\udc49 You feel sad if you have to scrap that prototype. \u2697\ufe0f Finally, you have to test that prototype. If your problem was clearly defined, you should know what a successful evaluation looks like. \ud83d\udcac This is not about software testing. Test the prototype with real people. Things to keep in mind: \ud83d\udc49 Shut up and watch, people should discover how the thing works by themselves. \ud83d\udc49 Test with a variety of different profiles. \ud83d\udc49 Write down every complaint you get, but don't mind about the proposed solutions. Once you reach this phase, you should have an answer to the question \"is this problem solved?\", which probably is: \ud83d\udd38 Somewhat, but the problem was not so well-defined as you thought. That great! You just completed one cycle and learnt something new. \ud83d\udd01 Now start over. \u26a1 Design Thinking applies not only to software but to any creative process. Whether you are planning an event, writing a book, building a physical gadget, or launching a service, you can use this strategy. This is not a bureaucratic methodology you have to follow, nor is a silver bullet. The key idea is this: \ud83d\udd11 You're trying to solve someone's problem, so you have to understand them first. Everything else is just tools to help you do that. As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/wisdomwednesday-designthinking Stay curious \ud83d\udd96 \ud83d\udd17 https://www.ideo.com/post/design-thinking \ud83d\udcc4 https://en.wikipedia.org/wiki/Design_thinking \ud83c\udfa5 https://youtu.be/UAinLaT42xY \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Design Thinking"},{"location":"tweetstorms/wisdomwednesday-teams/","text":"Today is #WisdomWednesday \ud83e\udd29! A moment to share ideas to help you improve. Today I want to talk about team-building. \u2753 How to build an effective team? It turns out, it's easier than you think \ud83e\uddf5\ud83d\udc47 \u2753 Let's start by answering, why do you need a team at all? Whether you're building a new product or service, writing a research paper, or just experimenting, teammates will be invaluable. Here are some non-obvious advantages to working with others rather than alone \ud83d\udc47 1\ufe0f\u20e3 You are less likely to quit On one hand, your teammates will support you when you feel like quitting. On the other hand, you'll feel responsible for them, and also kind of guilty for letting them down, which will encourage you to suck it up and keep going. 2\ufe0f\u20e3 You are less likely to really screw it Whatever the probability of discovering a very bad decision is, often is enough that someone else spots it and it becomes evident. More people means the chance of missing a fatal flaw is quickly multiplying down to zero. 3\ufe0f\u20e3 You'll enjoy the ride more There is simply nothing better than to show others what you've come up with. Having a team means you'll always have an audience to showcase whatever dumb or smart idea you have. \u2753 Ok, but, what kind of team are we talking about here? It doesn't matter if you have a tightly hierarchized organization or a very loose group of like-minded people. You only really have a team if everyone in the team agrees that it is a team. A team is a set of people with a single shared idea: \u2b50 Everyone in the team believes being part of the team makes them better than being alone. \u2753 So, how can you build an effective team? Well, according to our definition, it seems pretty straightforward. \ud83d\udc49 You just have to make sure everyone in the team wants to stay in the team, right? So what does this mean? \ud83d\udc47 \ud83c\udd70\ufe0f There is something only the team can give me Maybe other members have skills I lack. Maybe it takes more than one person to achieve something. In any case, there has to be something that I cannot do alone. Otherwise, I don't need the team at all. \ud83c\udd71\ufe0f There is something only I can give the team Maybe I have a unique skill, or maybe I just bring a different mindset, or maybe I'm the one who makes everyone laugh. Whatever it is, I need to feel the team needs as much as I need the team. \ud83e\udd14 As you can see, we haven't talked about common goals, strong leadership, or organizational methodologies. All of that is great to have, but not strictly necessary. Here's why \ud83d\udc47 \u274e Effective teams don't need a common goal. We just need our objectives to be complementary to each other. While trying to achieve mine, I help you achieve yours, and vice-versa. In an effective team, the net force is positive, even if not all goals are aligned. \u274e Effective teams don't need strong leaders. A strong leader can be incredibly helpful, but the right leader for a given situation can be a different person. In an effective team, the right leaders naturally emerge when the task demands it. \u274e Effective teams don't need explicit methodologies. SCRUM and agile methodologies are great, but not strictly necessary. Every task may require a different structure. In an effective team, communication channels grow organically among members and the structure is flexible. I started saying that building an effective team is easy. That was a blatant lie \ud83d\ude48. Building an effective team is hard, very hard. But the benefits are even greater. \ud83d\udcad Now share your thoughts. What are your experiences with teams you've been part of? As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/wisdomwednesday-teams \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Team Building"},{"location":"tweetstorms/wisdomwednesday-why/","text":"Today is #WisdomWednesday \ud83e\udd29! A moment to share ideas to help you improve. Today's topic is inspired by @simonsinek and @neiltyson . Let's talk about how to communicate an idea. The key insight is this: \ud83d\udd11 Start with Why! A path to effective communication! \ud83e\uddf5\ud83d\udc47 You have an amazing idea. Whether it is a solution to a problem you care deeply about or an incredible new insight, it doesn't matter how genius it is if you are the only one who cares. \u2753 Why? \u2b50 Because it's not enough to be right. You have to be effective. Being effective means to produce the desired effect . To have someone or something change some behaviour because of you. Making anything change is hard, but it is especially hard to do it with people. \ud83d\udc49 If your idea does not spark a change, then it is a dead idea. \u2753 What do you do then? \ud83d\udca1 You convince them that the problem you care about is also a problem they have or a problem they should care about. \u2753 How do you do it? \u2699\ufe0f Start by structuring your discourse for maximum impact. Whether it is a 1-minute pitch or a PhD viva, always start with the problem, and then build towards the solution. Answer these questions in this order: \u2b50 Why \ud83d\udca1 What \u2699\ufe0f How \u2b50 Connect with your audience: 1\ufe0f\u20e3 Use a story, preferably with people as protagonists 2\ufe0f\u20e3 Be explicit about the problem 3\ufe0f\u20e3 Layout the consequences of leaving that problem unsolved 4\ufe0f\u20e3 Be kind of dramatic (\ud83d\udc4d @josejorgexl ) 5\ufe0f\u20e3 Promise them something \ud83d\udca1 Get your main point across: \ud83d\uddbc\ufe0f Use graphics \u26a1\ufe0f Be concise \u2699\ufe0f You got them, now squeeze: 1\ufe0f\u20e3 Do not patronize your audience 2\ufe0f\u20e3 Use concrete and realistic examples 3\ufe0f\u20e3 Explain things as simple as possible, but not simpler 4\ufe0f\u20e3 Leave unimportant details unexplained 5\ufe0f\u20e3 Do not show off 6\ufe0f\u20e3 Always fulfil what you promised Once you have them convinced, leave with a Call to Action . Something your audience can do right there about that issue. \u26a1\ufe0f Start applying these insights today, in your emails, Twitter threads, or presentations, and give your communication skills a level-up! As usual, if you like this topic, reply in this thread or @ me at any time. Feel free to \u2764\ufe0f like and \ud83d\udd01 retweet if you think someone else could benefit from knowing this stuff. \ud83e\uddf5 Read this thread online at https://apiad.net/tweetstorms/wisdomwednesday-why Stay curious \ud83d\udd96 \ud83c\udfa5 https://youtu.be/qp0HIF3SfI4 \ud83c\udfa5 https://youtu.be/Tv0kQbOIrjY \ud83d\udcda https://simonsinek.com/product/start-with-why/ \ud83d\udcc4 https://simonsinek.com/commit/the-science-of-why/ \ud83d\udde8\ufe0f You can see this tweetstorm as originally posted in this Twitter thread .","title":"Start with Why"}]}